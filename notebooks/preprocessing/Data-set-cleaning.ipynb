{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8780e802f938c97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T13:34:45.381084Z",
     "start_time": "2025-11-09T13:34:45.379395Z"
    }
   },
   "source": [
    "## Importing the libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "778a637b838440c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T19:15:23.115859Z",
     "start_time": "2025-11-11T19:15:23.112921Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import re\n",
    "import xlsxwriter\n",
    "\n",
    "# Import statements for Functions.py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from src.python.Functions import describe_dataframes\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'src', 'python')))\n",
    "from Functions import *\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "8b622c9ade013314",
   "metadata": {},
   "source": [
    "## Importing the datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f20bf31bc77de70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:33:07.089222Z",
     "start_time": "2025-11-11T17:25:57.913648Z"
    }
   },
   "source": [
    "# Importing dataset of balance and P&L function:\n",
    "# Execution might take 10 minutes or more due to the large size of the datasets.\n",
    "# Cannot make pandas read csv without errors so we use openpyxl to read xlsx files.\n",
    "\n",
    "balance2025 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2025.xlsx')\n",
    "balance2024 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2024.xlsx')\n",
    "balance2023 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2023.xlsx')\n",
    "balance2022 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2022.xlsx')\n",
    "balance2021 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2021.xlsx')\n",
    "balance2020 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2020.xlsx')\n",
    "\n",
    "pnl2025 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2025.xlsx')\n",
    "pnl2024 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2024.xlsx')\n",
    "pnl2023 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2023.xlsx')\n",
    "pnl2022 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2022.xlsx')\n",
    "pnl2021 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2021.xlsx')\n",
    "pnl2020 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2020.xlsx')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9863e5bf1b1e5f22",
   "metadata": {},
   "source": [
    "### Fallbacks for large dfs:\n",
    "Run from here when you make changes to the dataframes to avoid memory errors and long file importing!"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4f6153048a8682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:33:07.310706Z",
     "start_time": "2025-11-11T17:33:07.185143Z"
    }
   },
   "source": [
    "\n",
    "# Fallbacks for large dfs:\n",
    "B2025 = balance2025.copy()\n",
    "B2024 = balance2024.copy()\n",
    "B2023 = balance2023.copy()\n",
    "B2022 = balance2022.copy()\n",
    "B2021 = balance2021.copy()\n",
    "B2020 = balance2020.copy()\n",
    "\n",
    "P2025 = pnl2025.copy()\n",
    "P2024 = pnl2024.copy()\n",
    "P2023 = pnl2023.copy()\n",
    "P2022 = pnl2022.copy()\n",
    "P2021 = pnl2021.copy()\n",
    "P2020 = pnl2020.copy()\n",
    "\n",
    "# Saving in lists for functions:\n",
    "balance_list = [B2025, B2024, B2023, B2022, B2021, B2020]\n",
    "pnl_list = [P2025, P2024, P2023, P2022, P2021, P2020]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "f27eec3673db73cd",
   "metadata": {},
   "source": [
    "## Cleaning the data with functions:\n",
    "#### Removing unnecessary columns:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6d2875c38ddb353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T19:16:09.136740Z",
     "start_time": "2025-11-11T19:16:09.118800Z"
    }
   },
   "source": [
    "# Unnecessary column removal from list of dataframes:\n",
    "def remove_mutual_unnecessary_columns(df_list):\n",
    "    for df in df_list:\n",
    "        bad_columns = ['ja_pavadinimas', 'obj_pav','form_pav','template_name',  'standard_name', 'form_pavadinimas','line_type_id', 'stat_pavadinimas', 'stat_pav']\n",
    "        for col in bad_columns:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=col, inplace=True)\n",
    "    return df_list\n",
    "\n",
    "# Removing unnecessary rows from list of dataframes:\n",
    "remove_mutual_unnecessary_columns(balance_list)\n",
    "remove_mutual_unnecessary_columns(pnl_list)\n",
    "\n",
    "# Renaming collumns to be the same across dataframes:\n",
    "def rename_columns(df_list):\n",
    "    for df in df_list:\n",
    "        # Rename 'obj_kodas' to 'ja_kodas' if it exists\n",
    "        if 'obj_kodas' in df.columns:\n",
    "            df.rename(columns={'obj_kodas': 'ja_kodas'}, inplace=True)\n",
    "\n",
    "        # Rename other columns if they exist\n",
    "        column_mapping = {\n",
    "            'nuosavas_kapitalas': 'NUOSAVAS KAPITALAS',\n",
    "            'mok_sumos_ir_isipareigojimai': 'MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI',\n",
    "            'trumpalaikis_turtas': 'TRUMPALAIKIS TURTAS',\n",
    "            'ilgalaikis_turtas': 'ILGALAIKIS TURTAS',\n",
    "            'pelnas_pries_apmokestinima': 'PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ',\n",
    "        'grynasis_pelnas': 'GRYNASIS PELNAS (NUOSTOLIAI)',\n",
    "        'pardavimo_pajamos': 'PARDAVIMO PAJAMOS'\n",
    "        }\n",
    "\n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in df.columns:\n",
    "                df.rename(columns={old_col: new_col}, inplace=True)\n",
    "\n",
    "    return df_list\n",
    "\n",
    "rename_columns(balance_list)\n",
    "rename_columns(pnl_list)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         ja_kodas  form_kodas  stat_kodas template_id standard_id  \\\n",
       " 0       110003978         310           0      FS0329      IST024   \n",
       " 1       110003978         310           0      FS0329      IST024   \n",
       " 2       110003978         310           0      FS0329      IST024   \n",
       " 3       110004884         310           0      FS0718      IST209   \n",
       " 4       110004884         310           0      FS0718      IST209   \n",
       " ...           ...         ...         ...         ...         ...   \n",
       " 423454  307123738         310           0      FS0329      IST024   \n",
       " 423455  307193537         960           0      FS0522      IST024   \n",
       " 423456  307193537         960           0      FS0522      IST024   \n",
       " 423457  307438075         960           0      FS0522      IST118   \n",
       " 423458  307438075         960           0      FS0522      IST118   \n",
       " \n",
       "                                       line_name  reiksme beginning_date  \\\n",
       " 0                             PARDAVIMO PAJAMOS    97545     2024-01-01   \n",
       " 1                  GRYNASIS PELNAS (NUOSTOLIAI)  2397510     2024-01-01   \n",
       " 2       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  2755467     2024-01-01   \n",
       " 3         ATASKAITINIŲ METŲ PELNAS (NUOSTOLIAI)   511543     2024-01-01   \n",
       " 4       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ   511543     2024-01-01   \n",
       " ...                                         ...      ...            ...   \n",
       " 423454  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ        0     2025-03-17   \n",
       " 423455             GRYNASIS PELNAS (NUOSTOLIAI)        0     2025-06-06   \n",
       " 423456  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ        0     2025-06-06   \n",
       " 423457             GRYNASIS PELNAS (NUOSTOLIAI)        0     2025-09-18   \n",
       " 423458  PELNAS (NUOSTOLIAI) PRIEš APMOKESTINIMą        0     2025-09-18   \n",
       " \n",
       "        turning_date    reg_date formavimo_data  \n",
       " 0        2024-12-31  2025-05-28     2025-11-03  \n",
       " 1        2024-12-31  2025-05-28     2025-11-03  \n",
       " 2        2024-12-31  2025-05-28     2025-11-03  \n",
       " 3        2024-12-31  2025-05-28     2025-11-03  \n",
       " 4        2024-12-31  2025-05-28     2025-11-03  \n",
       " ...             ...         ...            ...  \n",
       " 423454   2025-06-30  2025-10-31     2025-11-03  \n",
       " 423455   2025-07-22  2025-07-22     2025-11-03  \n",
       " 423456   2025-07-22  2025-07-22     2025-11-03  \n",
       " 423457   2025-10-22  2025-10-24     2025-11-03  \n",
       " 423458   2025-10-22  2025-10-24     2025-11-03  \n",
       " \n",
       " [423459 rows x 11 columns],\n",
       "          ja_kodas  form_kodas  stat_kodas template_id standard_id  \\\n",
       " 0       110003978         310           0      FS0229      IST024   \n",
       " 1       110003978         310           0      FS0229      IST024   \n",
       " 2       110003978         310           0      FS0229      IST024   \n",
       " 3       110004884         310           0      FS0618      IST209   \n",
       " 4       110004884         310           0      FS0618      IST209   \n",
       " ...           ...         ...         ...         ...         ...   \n",
       " 406750  306748060         960           7      FS0522      IST118   \n",
       " 406751  306748060         960           7      FS0522      IST118   \n",
       " 406752  306748060         960           7      FS0522      IST118   \n",
       " 406753  306815114         310           0      FS0229      IST024   \n",
       " 406754  306815114         310           0      FS0229      IST024   \n",
       " \n",
       "                                       line_name  reiksme beginning_date  \\\n",
       " 0       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ   -17980     2023-01-01   \n",
       " 1                  GRYNASIS PELNAS (NUOSTOLIAI)   -20409     2023-01-01   \n",
       " 2                             PARDAVIMO PAJAMOS    74824     2023-01-01   \n",
       " 3                             PARDAVIMO PAJAMOS  9701655     2023-01-01   \n",
       " 4       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  2151794     2023-01-01   \n",
       " ...                                         ...      ...            ...   \n",
       " 406750                        PARDAVIMO PAJAMOS       72     2024-05-08   \n",
       " 406751             GRYNASIS PELNAS (NUOSTOLIAI)     -198     2024-05-08   \n",
       " 406752  PELNAS (NUOSTOLIAI) PRIEš APMOKESTINIMą     -198     2024-05-08   \n",
       " 406753  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ    -2071     2024-06-03   \n",
       " 406754             GRYNASIS PELNAS (NUOSTOLIAI)    -2071     2024-06-03   \n",
       " \n",
       "        turning_date    reg_date formavimo_data  \n",
       " 0        2023-12-31  2024-05-23     2025-04-21  \n",
       " 1        2023-12-31  2024-05-23     2025-04-21  \n",
       " 2        2023-12-31  2024-05-23     2025-04-21  \n",
       " 3        2023-12-31  2024-06-03     2025-04-21  \n",
       " 4        2023-12-31  2024-06-03     2025-04-21  \n",
       " ...             ...         ...            ...  \n",
       " 406750   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406751   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406752   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406753   2024-06-30  2024-11-29     2025-04-21  \n",
       " 406754   2024-06-30  2024-11-29     2025-04-21  \n",
       " \n",
       " [406755 rows x 11 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       110003978         310              2      FS0229      IST024   \n",
       " 1       110004884         310              0      FS0618      IST209   \n",
       " 2       110005648         310              0      FS0229      IST024   \n",
       " 3       110006892         310              0      FS0229      IST024   \n",
       " 4       110008377         310              0      FS0229      IST024   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 141939  306370963         310              0      FS0422      IST118   \n",
       " 141940  306372583         960             10      FS0422      IST118   \n",
       " 141941  306384240         310              0      FS0229      IST024   \n",
       " 141942  306453633         960              0      FS0422      IST118   \n",
       " 141943  306600492         960              0      FS0422      IST118   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2022-01-01      2022-12-31  2023-05-24   \n",
       " 1           2022-01-01      2022-12-31  2023-06-30   \n",
       " 2           2022-01-01      2022-12-31  2023-05-15   \n",
       " 3           2022-01-01      2022-12-31  2023-06-16   \n",
       " 4           2022-01-01      2022-12-31  2023-05-23   \n",
       " ...                ...             ...         ...   \n",
       " 141939      2023-08-01      2023-11-30  2023-12-20   \n",
       " 141940      2023-08-02      2023-11-06  2023-11-09   \n",
       " 141941      2023-08-21      2023-09-14  2023-09-21   \n",
       " 141942      2023-09-26      2023-12-31  2023-12-31   \n",
       " 141943      2023-10-24      2023-12-28  2023-12-28   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                       15420.0                       13104.0   \n",
       " 1                                     -824210.0                           NaN   \n",
       " 2                                       14067.0                       11944.0   \n",
       " 3                                       14149.0                       13441.0   \n",
       " 4                                      159064.0                      135027.0   \n",
       " ...                                         ...                           ...   \n",
       " 141939                                  12142.0                       12142.0   \n",
       " 141940                                      0.0                           0.0   \n",
       " 141941                                      0.0                           0.0   \n",
       " 141942                                      0.0                           0.0   \n",
       " 141943                                      0.0                           0.0   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                 65196.0     2024-10-03  \n",
       " 1               8359577.0     2024-10-03  \n",
       " 2               1010501.0     2024-10-03  \n",
       " 3                167873.0     2024-10-03  \n",
       " 4                537185.0     2024-10-03  \n",
       " ...                   ...            ...  \n",
       " 141939            59125.0     2024-10-03  \n",
       " 141940                NaN     2024-10-03  \n",
       " 141941                NaN     2024-10-03  \n",
       " 141942                0.0     2024-10-03  \n",
       " 141943                NaN     2024-10-03  \n",
       " \n",
       " [141944 rows x 12 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       301011561         310              0      FS0129      IST024   \n",
       " 1       303641352         310              0      FS0129      IST024   \n",
       " 2       301684796         310              0      FS0128      IST023   \n",
       " 3       302502531         310              0      FS0129      IST024   \n",
       " 4       304590697         310              0      FS0129      IST024   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 123685  305189141         310              0      FS0129      IST024   \n",
       " 123686  304922605         960              0      FS0322      IST118   \n",
       " 123687  125935881         310              0      FS0129      IST024   \n",
       " 123688  300629576         310              0      FS0129      IST024   \n",
       " 123689  301507365         310              0      FS0129      IST024   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2021-01-01      2021-12-31  2022-01-02   \n",
       " 1           2021-01-01      2021-12-31  2022-05-27   \n",
       " 2           2021-01-01      2021-12-31  2022-06-29   \n",
       " 3           2021-01-01      2021-12-31  2022-05-30   \n",
       " 4           2021-01-01      2021-12-31  2022-04-21   \n",
       " ...                ...             ...         ...   \n",
       " 123685      2019-06-14      2019-12-31  2022-11-17   \n",
       " 123686      2021-01-01      2021-12-31  2022-02-25   \n",
       " 123687      2018-01-01      2018-12-31  2022-12-12   \n",
       " 123688      2021-01-01      2021-12-31  2022-06-23   \n",
       " 123689      2021-01-01      2021-12-31  2022-05-10   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                         -91.0                         -91.0   \n",
       " 1                                           0.0                           0.0   \n",
       " 2                                           NaN                           0.0   \n",
       " 3                                       20107.0                       18647.0   \n",
       " 4                                       78141.0                       74162.0   \n",
       " ...                                         ...                           ...   \n",
       " 123685                                      0.0                           0.0   \n",
       " 123686                                    461.0                         435.0   \n",
       " 123687                                      0.0                           0.0   \n",
       " 123688                                  79761.0                       67797.0   \n",
       " 123689                                  75692.0                       63564.0   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                     NaN     2023-03-01  \n",
       " 1                     NaN     2023-03-01  \n",
       " 2                     0.0     2023-03-01  \n",
       " 3               2163507.0     2023-03-01  \n",
       " 4                242465.0     2023-03-01  \n",
       " ...                   ...            ...  \n",
       " 123685                NaN     2023-03-01  \n",
       " 123686            44632.0     2023-03-01  \n",
       " 123687                NaN     2023-03-01  \n",
       " 123688          1733418.0     2023-03-01  \n",
       " 123689          4485193.0     2023-03-01  \n",
       " \n",
       " [123690 rows x 12 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       305390322         310              0      FS0128      IST023   \n",
       " 1       305213076         310              0      FS0128      IST023   \n",
       " 2       304088367         960              0      FS0322      IST118   \n",
       " 3       300094102         310              0      FS0129      IST024   \n",
       " 4       303219212         960              0      FS0322      IST118   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 110220  302686921         310              1      FS0128      IST023   \n",
       " 110221  303289125         310              7      FS0128      IST023   \n",
       " 110222  305333912         310              0      FS0129      IST024   \n",
       " 110223  304150413         310              0      FS0129      IST024   \n",
       " 110224  303226623         630              0      FS0323      IST117   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2019-12-11      2019-12-31  2021-05-27   \n",
       " 1           2019-07-18      2019-12-31  2021-09-08   \n",
       " 2           2020-01-01      2020-12-31  2021-03-31   \n",
       " 3           2020-01-01      2020-12-31  2021-06-10   \n",
       " 4           2020-01-01      2020-12-31  2021-07-12   \n",
       " ...                ...             ...         ...   \n",
       " 110220      2020-01-01      2020-12-31  2021-05-26   \n",
       " 110221      2020-01-01      2020-12-31  2021-03-30   \n",
       " 110222      2020-01-01      2020-12-31  2021-07-11   \n",
       " 110223      2020-01-01      2020-12-31  2021-05-31   \n",
       " 110224      2020-01-01      2020-12-31  2021-05-25   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                           NaN                           0.0   \n",
       " 1                                           NaN                       -8042.0   \n",
       " 2                                       20624.0                       19562.0   \n",
       " 3                                       72425.0                       70062.0   \n",
       " 4                                           0.0                           0.0   \n",
       " ...                                         ...                           ...   \n",
       " 110220                                      NaN                      -61659.0   \n",
       " 110221                                      NaN                           0.0   \n",
       " 110222                                  20903.0                       19881.0   \n",
       " 110223                                 -10215.0                      -10215.0   \n",
       " 110224                                      NaN                           NaN   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                     NaN     2023-03-01  \n",
       " 1                     NaN     2023-03-01  \n",
       " 2                 43780.0     2023-03-01  \n",
       " 3                155482.0     2023-03-01  \n",
       " 4                     NaN     2023-03-01  \n",
       " ...                   ...            ...  \n",
       " 110220           584174.0     2023-03-01  \n",
       " 110221                0.0     2023-03-01  \n",
       " 110222           142964.0     2023-03-01  \n",
       " 110223            97068.0     2023-03-01  \n",
       " 110224              376.0     2023-03-01  \n",
       " \n",
       " [110225 rows x 12 columns],\n",
       "         ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0      304406916         310              0      FS0129      IST024   \n",
       " 1      304064380         310              0      FS0128      IST023   \n",
       " 2      305186985         960              0      FS0322      IST118   \n",
       " 3      302915341         310              0      FS0129      IST024   \n",
       " 4      300846448         310              0      FS0129      IST024   \n",
       " ...          ...         ...            ...         ...         ...   \n",
       " 96610  302797423         310              0      FS0128      IST023   \n",
       " 96611  133553116         310              0      FS0128      IST023   \n",
       " 96612  304074296         310              0      FS0128      IST023   \n",
       " 96613  303199069         310              0      FS0129      IST024   \n",
       " 96614  302478692         310              0      FS0128      IST023   \n",
       " \n",
       "       laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0          2019-01-01      2019-12-31  2020-04-30   \n",
       " 1          2018-01-01      2018-12-31  2020-06-14   \n",
       " 2          2019-06-10      2019-12-31  2020-06-10   \n",
       " 3          2019-01-01      2019-12-31  2020-10-01   \n",
       " 4          2018-01-01      2018-12-31  2020-12-29   \n",
       " ...               ...             ...         ...   \n",
       " 96610      2018-01-01      2018-12-31  2020-05-04   \n",
       " 96611      2017-01-01      2017-12-31  2020-02-20   \n",
       " 96612      2019-01-01      2019-12-31  2020-05-14   \n",
       " 96613      2019-01-01      2019-12-31  2020-05-30   \n",
       " 96614      2019-01-01      2019-12-31  2020-05-19   \n",
       " \n",
       "        PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                     119356.0                      113384.0   \n",
       " 1                                          NaN                         479.0   \n",
       " 2                                          0.0                           0.0   \n",
       " 3                                      -2748.0                       -2748.0   \n",
       " 4                                          0.0                           0.0   \n",
       " ...                                        ...                           ...   \n",
       " 96610                                      NaN                        3252.0   \n",
       " 96611                                      NaN                        3621.0   \n",
       " 96612                                      NaN                        -318.0   \n",
       " 96613                                  72867.0                       69224.0   \n",
       " 96614                                      NaN                         218.0   \n",
       " \n",
       "        PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0               182596.0     2023-03-01  \n",
       " 1                17406.0     2023-03-01  \n",
       " 2                    NaN     2023-03-01  \n",
       " 3               170934.0     2023-03-01  \n",
       " 4                    NaN     2023-03-01  \n",
       " ...                  ...            ...  \n",
       " 96610           233772.0     2023-03-01  \n",
       " 96611            10580.0     2023-03-01  \n",
       " 96612                0.0     2023-03-01  \n",
       " 96613            75500.0     2023-03-01  \n",
       " 96614           478292.0     2023-03-01  \n",
       " \n",
       " [96615 rows x 12 columns]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "95312fa08ed7ae2e",
   "metadata": {},
   "source": [
    "#### Extracting columns line_name, reiksme and ja_kodas:\n",
    "This function is uneeded but if you need to view just the extracted columns, you can use it:"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d99a3f07c2c9d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:33:08.181716Z",
     "start_time": "2025-11-11T17:33:08.178140Z"
    }
   },
   "source": [
    "# Extracting columns line_name, reiksme and ja_kodas from dfs with all of this data:\n",
    "def extract_line_name_reiksme_ja_kodas(df_list):\n",
    "    \"\"\"\n",
    "    Extract columns 'line_name', 'reiksme', and 'ja_kodas' from DataFrames\n",
    "    that contain all three columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of pandas.DataFrame\n",
    "        List of DataFrames to process (will be modified in-place)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of pandas.DataFrame\n",
    "        List of DataFrames containing only the three specified columns\n",
    "    \"\"\"\n",
    "    extracted_dfs = []\n",
    "\n",
    "    required_columns = ['line_name', 'reiksme', 'ja_kodas']\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        # Check if all required columns exist in the current DataFrame\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            # Extract only the required columns\n",
    "            extracted_df = df[required_columns].copy()\n",
    "            extracted_dfs.append(extracted_df)\n",
    "\n",
    "\n",
    "        else:\n",
    "            missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "            print(f\"DataFrame {i}: Missing columns {missing_cols} - skipped\")\n",
    "\n",
    "    print(f\"\\nExtracted {len(extracted_dfs)} out of {len(df_list)} DataFrames\")\n",
    "    return extracted_dfs\n",
    "\"\"\" Uncomment to see the extracted columns:\n",
    "B_extracted = extract_line_name_reiksme_ja_kodas(balance_list)\n",
    "P_extracted = extract_line_name_reiksme_ja_kodas(pnl_list)\n",
    "\n",
    "# Renaming the extracted dfs to be more descriptive:\n",
    "B_extracted_2025 = B_extracted[0]\n",
    "B_extracted_2024 = B_extracted[1]\n",
    "\n",
    "P_extracted_2025 = P_extracted[0]\n",
    "P_extracted_2024 = P_extracted[1]\n",
    "\n",
    "# New lists with extracted and renamed dfs:\n",
    "B_extracted_renamed = [B_extracted_2025, B_extracted_2024]\n",
    "P_extracted_renamed = [P_extracted_2025, P_extracted_2024]\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Uncomment to see the extracted columns:\\nB_extracted = extract_line_name_reiksme_ja_kodas(balance_list)\\nP_extracted = extract_line_name_reiksme_ja_kodas(pnl_list)\\n\\n# Renaming the extracted dfs to be more descriptive:\\nB_extracted_2025 = B_extracted[0]\\nB_extracted_2024 = B_extracted[1]\\n\\nP_extracted_2025 = P_extracted[0]\\nP_extracted_2024 = P_extracted[1]\\n\\n# New lists with extracted and renamed dfs:\\nB_extracted_renamed = [B_extracted_2025, B_extracted_2024]\\nP_extracted_renamed = [P_extracted_2025, P_extracted_2024]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "30a3db0ea1422c0a",
   "metadata": {},
   "source": [
    "#### Shifting the column data of extraced dfs so that every row is unique with new columns:"
   ]
  },
  {
   "cell_type": "code",
   "id": "369daaa15c18235c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:33:09.279430Z",
     "start_time": "2025-11-11T17:33:08.298849Z"
    }
   },
   "source": [
    "# Pivoting the big dataframes:\n",
    "def pivot_dfs_smart(df_list):\n",
    "    \"\"\"\n",
    "    Apply pivot transformation with smart aggregation for different column types.\n",
    "    \"\"\"\n",
    "\n",
    "    def pivot_line_names_to_columns_smart(df):\n",
    "        \"\"\"\n",
    "        Pivot with intelligent aggregation based on column data types.\n",
    "        \"\"\"\n",
    "        # Identify column types for smart aggregation\n",
    "        numeric_columns = []\n",
    "        string_columns = []\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col in ['line_name', 'reiksme']:\n",
    "                continue\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                numeric_columns.append(col)\n",
    "            else:\n",
    "                string_columns.append(col)\n",
    "\n",
    "        # Create aggregation dictionary\n",
    "        aggregation_dict = {'reiksme': 'first'}\n",
    "\n",
    "        # For numeric columns, use 'first' or 'mean' depending on context\n",
    "        for col in numeric_columns:\n",
    "            aggregation_dict[col] = 'first'\n",
    "\n",
    "        # For string columns, use 'first' (take the first occurrence)\n",
    "        for col in string_columns:\n",
    "            aggregation_dict[col] = 'first'\n",
    "\n",
    "        # Identify index columns (all columns except line_name and reiksme)\n",
    "        index_columns = [col for col in df.columns if col not in ['line_name', 'reiksme']]\n",
    "\n",
    "        # Perform pivot\n",
    "        pivoted_df = df.pivot_table(\n",
    "            index=index_columns,\n",
    "            columns='line_name',\n",
    "            values='reiksme',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "\n",
    "        # Reset column names\n",
    "        pivoted_df.columns.name = None\n",
    "\n",
    "        return pivoted_df\n",
    "\n",
    "    pivoted_dfs = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            required_columns = ['line_name', 'reiksme', 'ja_kodas']\n",
    "            if not all(col in df.columns for col in required_columns):\n",
    "                missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "                print(f\"DataFrame {i}: Missing columns {missing_cols}\")\n",
    "                pivoted_dfs.append(df)\n",
    "                continue\n",
    "\n",
    "            print(f\"DataFrame {i}: Preserving {len(df.columns) - 2} columns in result\")\n",
    "\n",
    "            pivoted_df = pivot_line_names_to_columns_smart(df)\n",
    "            pivoted_dfs.append(pivoted_df)\n",
    "            print(f\"DataFrame {i}: Successfully pivoted. Original shape: {df.shape}, Pivoted shape: {pivoted_df.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"DataFrame {i}: Error during pivoting - {e}\")\n",
    "            pivoted_dfs.append(df)\n",
    "\n",
    "    return pivoted_dfs\n",
    "\n",
    "# Pivoting the balance dataframes:\n",
    "\n",
    "Bpivoted = pivot_dfs_smart(balance_list)\n",
    "\n",
    "# Pivoting the P&L dataframes:\n",
    "\n",
    "Ppivoted = pivot_dfs_smart(pnl_list)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Preserving 9 columns in result\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 11), Pivoted shape: (156318, 18)\n",
      "DataFrame 1: Preserving 9 columns in result\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 11), Pivoted shape: (153607, 18)\n",
      "DataFrame 2: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 0: Preserving 9 columns in result\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 11), Pivoted shape: (156318, 17)\n",
      "DataFrame 1: Preserving 9 columns in result\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 11), Pivoted shape: (153607, 17)\n",
      "DataFrame 2: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "6da87921479dbecd",
   "metadata": {},
   "source": [
    "### Checking duplicate rows in all dfs:\n",
    "\n",
    "This removes duplicate rows from all dfs and keeps only the most recent row for each ja_kodas, it keeps the new revision data. Older revisions are extracted and saved in a separate df."
   ]
  },
  {
   "cell_type": "code",
   "id": "4d5a00fcbbfcad10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:33:21.866782Z",
     "start_time": "2025-11-11T17:33:09.344857Z"
    }
   },
   "source": [
    "# Checking duplicate rows in all dfs and removing/extracting them:\n",
    "\n",
    "def extract_and_remove_older_duplicates(df_list, date_column='reg_date', id_column='ja_kodas'):\n",
    "    \"\"\"\n",
    "    Find duplicate ja_kodas rows, keep the most recent reg_date, and extract older duplicates.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of pandas.DataFrame\n",
    "        List of DataFrames to process\n",
    "    date_column : str, default 'reg_date'\n",
    "        Name of the date column to determine which rows to keep\n",
    "    id_column : str, default 'ja_kodas'\n",
    "        Name of the ID column to check for duplicates\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (cleaned_dfs, extracted_dfs, summary)\n",
    "        cleaned_dfs: List of DataFrames with only most recent rows kept\n",
    "        extracted_dfs: List of DataFrames containing the older duplicate rows\n",
    "        summary: Dictionary with statistics for each DataFrame\n",
    "    \"\"\"\n",
    "    cleaned_dfs = []\n",
    "    extracted_dfs = []\n",
    "    summary = {}\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            # Check if required columns exist\n",
    "            if id_column not in df.columns:\n",
    "                print(f\"DataFrame {i}: '{id_column}' column not found. Available: {list(df.columns)}\")\n",
    "                cleaned_dfs.append(df)\n",
    "                extracted_dfs.append(pd.DataFrame())  # Empty DataFrame for consistency\n",
    "                summary[i] = {'total_rows': len(df), 'duplicates_found': 0, 'kept': len(df), 'extracted': 0}\n",
    "                continue\n",
    "\n",
    "            if date_column not in df.columns:\n",
    "                print(f\"DataFrame {i}: '{date_column}' column not found. Available: {list(df.columns)}\")\n",
    "                cleaned_dfs.append(df)\n",
    "                extracted_dfs.append(pd.DataFrame())\n",
    "                summary[i] = {'total_rows': len(df), 'duplicates_found': 0, 'kept': len(df), 'extracted': 0}\n",
    "                continue\n",
    "\n",
    "            # Make a copy to avoid modifying original\n",
    "            df_working = df.copy()\n",
    "\n",
    "            # Ensure date_column is datetime\n",
    "            if not pd.api.types.is_datetime64_any_dtype(df_working[date_column]):\n",
    "                df_working[date_column] = pd.to_datetime(df_working[date_column], errors='coerce')\n",
    "                # Remove rows where date conversion failed\n",
    "                invalid_dates = df_working[date_column].isna().sum()\n",
    "                if invalid_dates > 0:\n",
    "                    print(f\"DataFrame {i}: {invalid_dates} rows with invalid dates will be treated as oldest\")\n",
    "\n",
    "            # Find duplicate ja_kodas\n",
    "            duplicate_mask = df_working.duplicated(subset=[id_column], keep=False)\n",
    "            duplicate_rows = df_working[duplicate_mask]\n",
    "\n",
    "            if len(duplicate_rows) == 0:\n",
    "                print(f\"DataFrame {i}: No duplicate {id_column} found\")\n",
    "                cleaned_dfs.append(df_working)\n",
    "                extracted_dfs.append(pd.DataFrame())\n",
    "                summary[i] = {'total_rows': len(df), 'duplicates_found': 0, 'kept': len(df), 'extracted': 0}\n",
    "                continue\n",
    "\n",
    "            # Group by ja_kodas and find the most recent date for each\n",
    "            duplicate_groups = duplicate_rows.groupby(id_column)\n",
    "\n",
    "            # Identify rows to keep (most recent date) and extract (older dates)\n",
    "            keep_indices = []\n",
    "            extract_indices = []\n",
    "\n",
    "            for ja_kodas, group in duplicate_groups:\n",
    "                if len(group) > 1:\n",
    "                    # Find the row with the most recent date\n",
    "                    most_recent_idx = group[date_column].idxmax()\n",
    "                    keep_indices.append(most_recent_idx)\n",
    "\n",
    "                    # Extract all other rows (older dates)\n",
    "                    older_indices = group.index[group.index != most_recent_idx].tolist()\n",
    "                    extract_indices.extend(older_indices)\n",
    "\n",
    "            # Create DataFrames\n",
    "            keep_df = df_working[~df_working.index.isin(extract_indices)]  # All non-extracted rows\n",
    "            extract_df = df_working[df_working.index.isin(extract_indices)]  # Only extracted rows\n",
    "\n",
    "            # Also include non-duplicate rows in keep_df\n",
    "            non_duplicate_rows = df_working[~duplicate_mask]\n",
    "            final_keep_df = pd.concat([keep_df, non_duplicate_rows], ignore_index=True)\n",
    "\n",
    "            cleaned_dfs.append(final_keep_df)\n",
    "            extracted_dfs.append(extract_df)\n",
    "\n",
    "            # Summary statistics\n",
    "            summary[i] = {\n",
    "                'total_rows': len(df),\n",
    "                'duplicates_found': len(duplicate_rows),\n",
    "                'unique_duplicate_ids': duplicate_rows[id_column].nunique(),\n",
    "                'kept': len(final_keep_df),\n",
    "                'extracted': len(extract_df),\n",
    "                'example_extracted': extract_df[id_column].value_counts().head(3).to_dict() if len(extract_df) > 0 else {}\n",
    "            }\n",
    "\n",
    "            print(f\"DataFrame {i}: Kept {len(final_keep_df)} rows, extracted {len(extract_df)} older duplicates\")\n",
    "            if len(extract_df) > 0:\n",
    "                print(f\"  Extracted {extract_df[id_column].nunique()} unique {id_column}s with older dates\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"DataFrame {i}: Error processing - {e}\")\n",
    "            cleaned_dfs.append(df)\n",
    "            extracted_dfs.append(pd.DataFrame())\n",
    "            summary[i] = {'total_rows': len(df), 'duplicates_found': 0, 'kept': len(df), 'extracted': 0, 'error': str(e)}\n",
    "\n",
    "    # Final summary\n",
    "    total_extracted = sum(s['extracted'] for s in summary.values())\n",
    "    total_duplicates = sum(s['duplicates_found'] for s in summary.values())\n",
    "\n",
    "    print(f\"\\n=== EXTRACTION SUMMARY ===\")\n",
    "    print(f\"Total DataFrames processed: {len(df_list)}\")\n",
    "    print(f\"Total duplicate rows found: {total_duplicates}\")\n",
    "    print(f\"Total older rows extracted: {total_extracted}\")\n",
    "\n",
    "    return cleaned_dfs, extracted_dfs, summary\n",
    "\n",
    "# Balance data:\n",
    "cleanedB, extractedB, summaryB = extract_and_remove_older_duplicates(Bpivoted)\n",
    "\n",
    "# P&L data:\n",
    "cleanedP, extractedP, summaryP = extract_and_remove_older_duplicates(Ppivoted)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Kept 285413 rows, extracted 9806 older duplicates\n",
      "  Extracted 7611 unique ja_kodass with older dates\n",
      "DataFrame 1: Kept 273341 rows, extracted 12292 older duplicates\n",
      "  Extracted 9289 unique ja_kodass with older dates\n",
      "DataFrame 2: Kept 175078 rows, extracted 152850 older duplicates\n",
      "  Extracted 128160 unique ja_kodass with older dates\n",
      "DataFrame 3: Kept 227434 rows, extracted 21325 older duplicates\n",
      "  Extracted 10710 unique ja_kodass with older dates\n",
      "DataFrame 4: Kept 204568 rows, extracted 14073 older duplicates\n",
      "  Extracted 8982 unique ja_kodass with older dates\n",
      "DataFrame 5: Kept 187052 rows, extracted 9965 older duplicates\n",
      "  Extracted 5652 unique ja_kodass with older dates\n",
      "\n",
      "=== EXTRACTION SUMMARY ===\n",
      "Total DataFrames processed: 6\n",
      "Total duplicate rows found: 390715\n",
      "Total older rows extracted: 220311\n",
      "DataFrame 0: Kept 285413 rows, extracted 9806 older duplicates\n",
      "  Extracted 7611 unique ja_kodass with older dates\n",
      "DataFrame 1: Kept 273341 rows, extracted 12292 older duplicates\n",
      "  Extracted 9289 unique ja_kodass with older dates\n",
      "DataFrame 2: Kept 226983 rows, extracted 22447 older duplicates\n",
      "  Extracted 12011 unique ja_kodass with older dates\n",
      "DataFrame 3: Kept 206757 rows, extracted 16083 older duplicates\n",
      "  Extracted 8457 unique ja_kodass with older dates\n",
      "DataFrame 4: Kept 188062 rows, extracted 12261 older duplicates\n",
      "  Extracted 7866 unique ja_kodass with older dates\n",
      "DataFrame 5: Kept 171681 rows, extracted 8383 older duplicates\n",
      "  Extracted 4783 unique ja_kodass with older dates\n",
      "\n",
      "=== EXTRACTION SUMMARY ===\n",
      "Total DataFrames processed: 6\n",
      "Total duplicate rows found: 131289\n",
      "Total older rows extracted: 81272\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "f80e539a2a1c4eac",
   "metadata": {},
   "source": [
    "## Adding PnL data to balance data:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5497bebf8372e3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:39:48.298766Z",
     "start_time": "2025-11-11T17:39:46.838486Z"
    }
   },
   "source": [
    "def merge_pnl_and_balances(df_list1, df_list2, how='inner'):\n",
    "    \"\"\"\n",
    "    Merge two lists of DataFrames on ja_kodas column with comprehensive diagnostics and validation.\n",
    "    Each DataFrame from list1 is merged with corresponding DataFrame from list2.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list1, df_list2 : list of pandas.DataFrame\n",
    "        Lists of DataFrames to merge\n",
    "    how : str, default 'inner'\n",
    "        Type of merge: 'inner', 'left', 'right', 'outer'\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of pandas.DataFrame\n",
    "        List of merged DataFrames\n",
    "    \"\"\"\n",
    "    if len(df_list1) != len(df_list2):\n",
    "        print(f\"Warning: List lengths differ - list1: {len(df_list1)}, list2: {len(df_list2)}\")\n",
    "        # Use the minimum length to avoid index errors\n",
    "        min_length = min(len(df_list1), len(df_list2))\n",
    "        df_list1 = df_list1[:min_length]\n",
    "        df_list2 = df_list2[:min_length]\n",
    "\n",
    "    merged_dfs = []\n",
    "\n",
    "    for i, (df1, df2) in enumerate(zip(df_list1, df_list2)):\n",
    "        try:\n",
    "            # Check if ja_kodas exists in both DataFrames\n",
    "            if 'ja_kodas' not in df1.columns:\n",
    "                print(f\"Pair {i}: ja_kodas not found in first DataFrame, skipping\")\n",
    "                continue\n",
    "            if 'ja_kodas' not in df2.columns:\n",
    "                print(f\"Pair {i}: ja_kodas not found in second DataFrame, skipping\")\n",
    "                continue\n",
    "\n",
    "            # Create copies to avoid modifying originals\n",
    "            df1_clean = df1.copy()\n",
    "            df2_clean = df2.copy()\n",
    "\n",
    "            # Validate ja_kodas data types and convert if necessary\n",
    "            if df1_clean['ja_kodas'].dtype != df2_clean['ja_kodas'].dtype:\n",
    "                print(f\"Pair {i}: ja_kodas data types differ - converting both to string\")\n",
    "                df1_clean['ja_kodas'] = df1_clean['ja_kodas'].astype(str)\n",
    "                df2_clean['ja_kodas'] = df2_clean['ja_kodas'].astype(str)\n",
    "\n",
    "            # Check for duplicate ja_kodas within each DataFrame\n",
    "            df1_duplicates = df1_clean.duplicated(subset=['ja_kodas']).sum()\n",
    "            df2_duplicates = df2_clean.duplicated(subset=['ja_kodas']).sum()\n",
    "\n",
    "            if df1_duplicates > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df1_duplicates} duplicate ja_kodas found in first DataFrame\")\n",
    "                # Keep first occurrence of duplicates\n",
    "                df1_clean = df1_clean.drop_duplicates(subset=['ja_kodas'], keep='first')\n",
    "\n",
    "            if df2_duplicates > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df2_duplicates} duplicate ja_kodas found in second DataFrame\")\n",
    "                # Keep first occurrence of duplicates\n",
    "                df2_clean = df2_clean.drop_duplicates(subset=['ja_kodas'], keep='first')\n",
    "\n",
    "            # Check for NaN values in ja_kodas\n",
    "            df1_nan = df1_clean['ja_kodas'].isna().sum()\n",
    "            df2_nan = df2_clean['ja_kodas'].isna().sum()\n",
    "\n",
    "            if df1_nan > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df1_nan} NaN values in ja_kodas (first DataFrame), removing\")\n",
    "                df1_clean = df1_clean.dropna(subset=['ja_kodas'])\n",
    "\n",
    "            if df2_nan > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df2_nan} NaN values in ja_kodas (second DataFrame), removing\")\n",
    "                df2_clean = df2_clean.dropna(subset=['ja_kodas'])\n",
    "\n",
    "            # Pre-merge diagnostics\n",
    "            df1_unique = df1_clean['ja_kodas'].nunique()\n",
    "            df2_unique = df2_clean['ja_kodas'].nunique()\n",
    "            common_ja_kodas = set(df1_clean['ja_kodas']) & set(df2_clean['ja_kodas'])\n",
    "            common_count = len(common_ja_kodas)\n",
    "\n",
    "            print(f\"\\n--- Pair {i} Merge Diagnostics ---\")\n",
    "            print(f\"DF1: {len(df1_clean)} rows, {df1_unique} unique ja_kodas\")\n",
    "            print(f\"DF2: {len(df2_clean)} rows, {df2_unique} unique ja_kodas\")\n",
    "            print(f\"Common ja_kodas: {common_count}\")\n",
    "            print(f\"Merge type: {how}\")\n",
    "\n",
    "            # Calculate expected result sizes\n",
    "            if how == 'inner':\n",
    "                expected_rows = common_count\n",
    "            elif how == 'left':\n",
    "                expected_rows = len(df1_clean)\n",
    "            elif how == 'right':\n",
    "                expected_rows = len(df2_clean)\n",
    "            else:  # outer\n",
    "                expected_rows = len(df1_clean) + len(df2_clean) - common_count\n",
    "\n",
    "            print(f\"Expected result rows: {expected_rows}\")\n",
    "\n",
    "            # Perform the merge with indicator to track sources\n",
    "            merged_df = pd.merge(\n",
    "                df1_clean,\n",
    "                df2_clean,\n",
    "                on='ja_kodas',\n",
    "                how=how,\n",
    "                suffixes=('_pnl', '_balance'),\n",
    "                indicator=True  # Add merge indicator column\n",
    "            )\n",
    "\n",
    "            # Post-merge diagnostics\n",
    "            actual_rows = len(merged_df)\n",
    "            merge_stats = merged_df['_merge'].value_counts()\n",
    "\n",
    "            print(f\"Actual result rows: {actual_rows}\")\n",
    "            print(f\"Merge composition: {merge_stats.to_dict()}\")\n",
    "\n",
    "            if actual_rows != expected_rows:\n",
    "                print(f\"WARNING: Expected {expected_rows} rows but got {actual_rows} rows\")\n",
    "\n",
    "            # Remove the indicator column\n",
    "            merged_df = merged_df.drop('_merge', axis=1)\n",
    "\n",
    "            # Check for overlapping column names (besides ja_kodas)\n",
    "            overlapping_cols = set(df1_clean.columns) & set(df2_clean.columns) - {'ja_kodas'}\n",
    "            if overlapping_cols:\n",
    "                print(f\"Overlapping columns (received suffixes): {list(overlapping_cols)}\")\n",
    "\n",
    "            print(f\"Pair {i}: Successfully merged. Shapes: {df1.shape} + {df2.shape} -> {merged_df.shape}\")\n",
    "\n",
    "            merged_dfs.append(merged_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Pair {i}: Error during merge - {e}\")\n",
    "            print(f\"Pair {i}: DF1 columns: {list(df1.columns) if 'df1' in locals() else 'N/A'}\")\n",
    "            print(f\"Pair {i}: DF2 columns: {list(df2.columns) if 'df2' in locals() else 'N/A'}\")\n",
    "            # Keep both original DataFrames if merge fails\n",
    "            merged_dfs.extend([df1, df2])\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\n=== MERGE SUMMARY ===\")\n",
    "    print(f\"Successfully processed: {len(merged_dfs)} DataFrames\")\n",
    "    print(f\"Total input pairs: {min(len(df_list1), len(df_list2))}\")\n",
    "\n",
    "    return merged_dfs\n",
    "\n",
    "# Merge the cleaned balance and P&L data:\n",
    "MergedData = merge_pnl_and_balances(cleanedB, cleanedP)\n",
    "\n",
    "# Merging the cleaned balance and P&L data but with outer merge (all rows are kept):\n",
    "# Seems to be the same as inner merge, I don't know why.\n",
    "MergedDataAll = merge_pnl_and_balances(cleanedB, cleanedP, how='outer')\n",
    "\n",
    "# Renaming dfs in MergedData to be more descriptive:\n",
    "\n",
    "MergedBP2025 = MergedData[0]\n",
    "MergedBP2024 = MergedData[1]\n",
    "MergedBP2023 = MergedData[2]\n",
    "MergedBP2022 = MergedData[3]\n",
    "MergedBP2021 = MergedData[4]\n",
    "MergedBP2020 = MergedData[5]\n",
    "\n",
    "MergedBPall2025 = MergedDataAll[0]\n",
    "MergedBPall2024 = MergedDataAll[1]\n",
    "MergedBPall2023 = MergedDataAll[2]\n",
    "MergedBPall2022 = MergedDataAll[3]\n",
    "MergedBPall2021 = MergedDataAll[4]\n",
    "MergedBPall2020 = MergedDataAll[5]\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 0: WARNING - 138901 duplicate ja_kodas found in first DataFrame\n",
      "Pair 0: WARNING - 138901 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 146512 rows, 146512 unique ja_kodas\n",
      "DF2: 146512 rows, 146512 unique ja_kodas\n",
      "Common ja_kodas: 146512\n",
      "Merge type: inner\n",
      "Expected result rows: 146512\n",
      "Actual result rows: 146512\n",
      "Merge composition: {'both': 146512, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'stat_kodas', 'beginning_date', 'template_id', 'turning_date', 'form_kodas', 'reg_date']\n",
      "Pair 0: Successfully merged. Shapes: (285413, 18) + (285413, 17) -> (146512, 34)\n",
      "Pair 1: WARNING - 132026 duplicate ja_kodas found in first DataFrame\n",
      "Pair 1: WARNING - 132026 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 141315 rows, 141315 unique ja_kodas\n",
      "DF2: 141315 rows, 141315 unique ja_kodas\n",
      "Common ja_kodas: 141315\n",
      "Merge type: inner\n",
      "Expected result rows: 141315\n",
      "Actual result rows: 141315\n",
      "Merge composition: {'both': 141315, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'stat_kodas', 'beginning_date', 'template_id', 'turning_date', 'form_kodas', 'reg_date']\n",
      "Pair 1: Successfully merged. Shapes: (273341, 18) + (273341, 17) -> (141315, 34)\n",
      "Pair 2: WARNING - 23459 duplicate ja_kodas found in first DataFrame\n",
      "Pair 2: WARNING - 107486 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 151619 rows, 151619 unique ja_kodas\n",
      "DF2: 119497 rows, 119497 unique ja_kodas\n",
      "Common ja_kodas: 119497\n",
      "Merge type: inner\n",
      "Expected result rows: 119497\n",
      "Actual result rows: 119497\n",
      "Merge composition: {'both': 119497, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 2: Successfully merged. Shapes: (175078, 13) + (226983, 12) -> (119497, 24)\n",
      "Pair 3: WARNING - 108362 duplicate ja_kodas found in first DataFrame\n",
      "Pair 3: WARNING - 99150 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 119072 rows, 119072 unique ja_kodas\n",
      "DF2: 107607 rows, 107607 unique ja_kodas\n",
      "Common ja_kodas: 107607\n",
      "Merge type: inner\n",
      "Expected result rows: 107607\n",
      "Actual result rows: 107607\n",
      "Merge composition: {'both': 107607, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 3: Successfully merged. Shapes: (227434, 13) + (206757, 12) -> (107607, 24)\n",
      "Pair 4: WARNING - 97793 duplicate ja_kodas found in first DataFrame\n",
      "Pair 4: WARNING - 90098 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 106775 rows, 106775 unique ja_kodas\n",
      "DF2: 97964 rows, 97964 unique ja_kodas\n",
      "Common ja_kodas: 97964\n",
      "Merge type: inner\n",
      "Expected result rows: 97964\n",
      "Actual result rows: 97964\n",
      "Merge composition: {'both': 97964, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 4: Successfully merged. Shapes: (204568, 13) + (188062, 12) -> (97964, 24)\n",
      "Pair 5: WARNING - 90700 duplicate ja_kodas found in first DataFrame\n",
      "Pair 5: WARNING - 83449 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 96352 rows, 96352 unique ja_kodas\n",
      "DF2: 88232 rows, 88232 unique ja_kodas\n",
      "Common ja_kodas: 88232\n",
      "Merge type: inner\n",
      "Expected result rows: 88232\n",
      "Actual result rows: 88232\n",
      "Merge composition: {'both': 88232, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 5: Successfully merged. Shapes: (187052, 13) + (171681, 12) -> (88232, 24)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "Successfully processed: 6 DataFrames\n",
      "Total input pairs: 6\n",
      "Pair 0: WARNING - 138901 duplicate ja_kodas found in first DataFrame\n",
      "Pair 0: WARNING - 138901 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 146512 rows, 146512 unique ja_kodas\n",
      "DF2: 146512 rows, 146512 unique ja_kodas\n",
      "Common ja_kodas: 146512\n",
      "Merge type: outer\n",
      "Expected result rows: 146512\n",
      "Actual result rows: 146512\n",
      "Merge composition: {'both': 146512, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'stat_kodas', 'beginning_date', 'template_id', 'turning_date', 'form_kodas', 'reg_date']\n",
      "Pair 0: Successfully merged. Shapes: (285413, 18) + (285413, 17) -> (146512, 34)\n",
      "Pair 1: WARNING - 132026 duplicate ja_kodas found in first DataFrame\n",
      "Pair 1: WARNING - 132026 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 141315 rows, 141315 unique ja_kodas\n",
      "DF2: 141315 rows, 141315 unique ja_kodas\n",
      "Common ja_kodas: 141315\n",
      "Merge type: outer\n",
      "Expected result rows: 141315\n",
      "Actual result rows: 141315\n",
      "Merge composition: {'both': 141315, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'stat_kodas', 'beginning_date', 'template_id', 'turning_date', 'form_kodas', 'reg_date']\n",
      "Pair 1: Successfully merged. Shapes: (273341, 18) + (273341, 17) -> (141315, 34)\n",
      "Pair 2: WARNING - 23459 duplicate ja_kodas found in first DataFrame\n",
      "Pair 2: WARNING - 107486 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 151619 rows, 151619 unique ja_kodas\n",
      "DF2: 119497 rows, 119497 unique ja_kodas\n",
      "Common ja_kodas: 119497\n",
      "Merge type: outer\n",
      "Expected result rows: 151619\n",
      "Actual result rows: 151619\n",
      "Merge composition: {'both': 119497, 'left_only': 32122, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 2: Successfully merged. Shapes: (175078, 13) + (226983, 12) -> (151619, 24)\n",
      "Pair 3: WARNING - 108362 duplicate ja_kodas found in first DataFrame\n",
      "Pair 3: WARNING - 99150 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 119072 rows, 119072 unique ja_kodas\n",
      "DF2: 107607 rows, 107607 unique ja_kodas\n",
      "Common ja_kodas: 107607\n",
      "Merge type: outer\n",
      "Expected result rows: 119072\n",
      "Actual result rows: 119072\n",
      "Merge composition: {'both': 107607, 'left_only': 11465, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 3: Successfully merged. Shapes: (227434, 13) + (206757, 12) -> (119072, 24)\n",
      "Pair 4: WARNING - 97793 duplicate ja_kodas found in first DataFrame\n",
      "Pair 4: WARNING - 90098 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 106775 rows, 106775 unique ja_kodas\n",
      "DF2: 97964 rows, 97964 unique ja_kodas\n",
      "Common ja_kodas: 97964\n",
      "Merge type: outer\n",
      "Expected result rows: 106775\n",
      "Actual result rows: 106775\n",
      "Merge composition: {'both': 97964, 'left_only': 8811, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 4: Successfully merged. Shapes: (204568, 13) + (188062, 12) -> (106775, 24)\n",
      "Pair 5: WARNING - 90700 duplicate ja_kodas found in first DataFrame\n",
      "Pair 5: WARNING - 83449 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 96352 rows, 96352 unique ja_kodas\n",
      "DF2: 88232 rows, 88232 unique ja_kodas\n",
      "Common ja_kodas: 88232\n",
      "Merge type: outer\n",
      "Expected result rows: 96352\n",
      "Actual result rows: 96352\n",
      "Merge composition: {'both': 88232, 'left_only': 8120, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['formavimo_data', 'standard_id', 'laikotarpis_iki', 'stat_statusas', 'laikotarpis_nuo', 'template_id', 'form_kodas', 'reg_date']\n",
      "Pair 5: Successfully merged. Shapes: (187052, 13) + (171681, 12) -> (96352, 24)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "Successfully processed: 6 DataFrames\n",
      "Total input pairs: 6\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data validation:",
   "id": "7bcef9027635fb9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T19:05:02.405304Z",
     "start_time": "2025-11-11T19:05:01.560814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#describe_dataframes(MergedData)\n",
    "\n",
    "describe_dataframes(MergedDataAll)"
   ],
   "id": "cce5c8e156072d1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  dataframe_name    rows  columns  total_cells  memory_mb  \\\n",
       "0           df_0  146512       34      4981408     107.03   \n",
       "1           df_1  141315       34      4804710     103.23   \n",
       "2           df_2  151619       24      3638856      95.30   \n",
       "3           df_3  119072       24      2857728      76.51   \n",
       "4           df_4  106775       24      2562600      68.79   \n",
       "5           df_5   96352       24      2312448      62.05   \n",
       "\n",
       "   ja_kodas_column_exists  ja_kodas_duplicates  ja_kodas_total_duplicate_rows  \\\n",
       "0                    True                    0                              0   \n",
       "1                    True                    0                              0   \n",
       "2                    True                    0                              0   \n",
       "3                    True                    0                              0   \n",
       "4                    True                    0                              0   \n",
       "5                    True                    0                              0   \n",
       "\n",
       "   ja_kodas_unique_duplicate_values  ja_kodas_duplicate_percentage  \\\n",
       "0                                 0                            0.0   \n",
       "1                                 0                            0.0   \n",
       "2                                 0                            0.0   \n",
       "3                                 0                            0.0   \n",
       "4                                 0                            0.0   \n",
       "5                                 0                            0.0   \n",
       "\n",
       "  ja_kodas_most_common_duplicate  ja_kodas_most_common_count  \\\n",
       "0                           None                           0   \n",
       "1                           None                           0   \n",
       "2                           None                           0   \n",
       "3                           None                           0   \n",
       "4                           None                           0   \n",
       "5                           None                           0   \n",
       "\n",
       "   total_missing_values  missing_percentage  numeric_columns  \\\n",
       "0               1513255               30.38               22   \n",
       "1               1469938               30.59               22   \n",
       "2                456253               12.54               12   \n",
       "3                207649                7.27               12   \n",
       "4                165737                6.47               12   \n",
       "5                147251                6.37               12   \n",
       "\n",
       "   categorical_columns  unique_dtypes  \n",
       "0                   10              4  \n",
       "1                   10              4  \n",
       "2                   10              4  \n",
       "3                   10              4  \n",
       "4                   10              4  \n",
       "5                   10              4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_name</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "      <th>total_cells</th>\n",
       "      <th>memory_mb</th>\n",
       "      <th>ja_kodas_column_exists</th>\n",
       "      <th>ja_kodas_duplicates</th>\n",
       "      <th>ja_kodas_total_duplicate_rows</th>\n",
       "      <th>ja_kodas_unique_duplicate_values</th>\n",
       "      <th>ja_kodas_duplicate_percentage</th>\n",
       "      <th>ja_kodas_most_common_duplicate</th>\n",
       "      <th>ja_kodas_most_common_count</th>\n",
       "      <th>total_missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>numeric_columns</th>\n",
       "      <th>categorical_columns</th>\n",
       "      <th>unique_dtypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_0</td>\n",
       "      <td>146512</td>\n",
       "      <td>34</td>\n",
       "      <td>4981408</td>\n",
       "      <td>107.03</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1513255</td>\n",
       "      <td>30.38</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_1</td>\n",
       "      <td>141315</td>\n",
       "      <td>34</td>\n",
       "      <td>4804710</td>\n",
       "      <td>103.23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1469938</td>\n",
       "      <td>30.59</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_2</td>\n",
       "      <td>151619</td>\n",
       "      <td>24</td>\n",
       "      <td>3638856</td>\n",
       "      <td>95.30</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>456253</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_3</td>\n",
       "      <td>119072</td>\n",
       "      <td>24</td>\n",
       "      <td>2857728</td>\n",
       "      <td>76.51</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>207649</td>\n",
       "      <td>7.27</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_4</td>\n",
       "      <td>106775</td>\n",
       "      <td>24</td>\n",
       "      <td>2562600</td>\n",
       "      <td>68.79</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>165737</td>\n",
       "      <td>6.47</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>df_5</td>\n",
       "      <td>96352</td>\n",
       "      <td>24</td>\n",
       "      <td>2312448</td>\n",
       "      <td>62.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>147251</td>\n",
       "      <td>6.37</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interim data export:\n",
    "Notebook is getting too long and confusing, so I will export the interim data to csv files."
   ],
   "id": "e86d9f45953da6e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T19:04:02.329090Z",
     "start_time": "2025-11-11T19:03:53.122060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exporting the interim data to csv files:\n",
    "\n",
    "save_df_list_to_csv_auto(MergedData, '../../data/interim/joined-balance-and-PnL/joined-only-matching-ja-kodas')\n",
    "\n",
    "save_df_list_to_csv_auto(MergedDataAll, '../../data/interim/joined-balance-and-PnL/joined-all-ja-kodas')"
   ],
   "id": "1457d0509ae9824e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MergedBPall2025',\n",
       " 'MergedBPall2024',\n",
       " 'MergedBPall2023',\n",
       " 'MergedBPall2022',\n",
       " 'MergedBPall2021',\n",
       " 'MergedBPall2020']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
