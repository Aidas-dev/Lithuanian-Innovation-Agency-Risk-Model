{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T13:34:45.381084Z",
     "start_time": "2025-11-09T13:34:45.379395Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Importing the libraries:\n",
   "id": "c8780e802f938c97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:10:34.665876Z",
     "start_time": "2025-11-10T21:10:34.249274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import xlsxwriter"
   ],
   "id": "177da610cc9a43aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing the datasets:\n",
   "id": "36460a672183c93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:17:00.574260Z",
     "start_time": "2025-11-10T21:10:34.669777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing dataset of balance and P&L function:\n",
    "# Execution might take 10 minutes or more due to the large size of the datasets.\n",
    "\n",
    "balance2025 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2025.xlsx')\n",
    "balance2024 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2024.xlsx')\n",
    "balance2023 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2023.xlsx')\n",
    "balance2022 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2022.xlsx')\n",
    "balance2021 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2021.xlsx')\n",
    "balance2020 = pd.read_excel('../../data/raw/firm-balance-statements/JAR_FA_RODIKLIAI_BLNS_2020.xlsx')\n",
    "\n",
    "pnl2025 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2025.xlsx')\n",
    "pnl2024 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2024.xlsx')\n",
    "pnl2023 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2023.xlsx')\n",
    "pnl2022 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2022.xlsx')\n",
    "pnl2021 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2021.xlsx')\n",
    "pnl2020 = pd.read_excel('../../data/raw/firm-PnL-statements/JAR_FA_RODIKLIAI_PLNA_2020.xlsx')"
   ],
   "id": "fb0a43f9a36c37c8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fallbacks for large dfs:",
   "id": "344738ef8ba7e5fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:14.134533Z",
     "start_time": "2025-11-10T21:20:14.001027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Fallbacks for large dfs:\n",
    "B2025 = balance2025.copy()\n",
    "B2024 = balance2024.copy()\n",
    "B2023 = balance2023.copy()\n",
    "B2022 = balance2022.copy()\n",
    "B2021 = balance2021.copy()\n",
    "B2020 = balance2020.copy()\n",
    "\n",
    "P2025 = pnl2025.copy()\n",
    "P2024 = pnl2024.copy()\n",
    "P2023 = pnl2023.copy()\n",
    "P2022 = pnl2022.copy()\n",
    "P2021 = pnl2021.copy()\n",
    "P2020 = pnl2020.copy()\n",
    "\n",
    "# Saving in lists for functions:\n",
    "balance_list = [B2025, B2024, B2023, B2022, B2021, B2020]\n",
    "pnl_list = [P2025, P2024, P2023, P2022, P2021, P2020]"
   ],
   "id": "e61e7d1332a0ffcb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cleaning the data with functions:\n",
    "#### Removing unnecessary columns:"
   ],
   "id": "c27c3c10c79e9598"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:14.909699Z",
     "start_time": "2025-11-10T21:20:14.144590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Unnecessary column removal from list of dataframes:\n",
    "def remove_mutual_unnecessary_columns(df_list):\n",
    "    for df in df_list:\n",
    "        remove_columns = ['ja_pavadinimas', 'obj_pav','form_pav','template_name',  'standard_name', 'form_pavadinimas','line_type_id', 'stat_pavadinimas', 'stat_pav']\n",
    "        for col in remove_columns:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=col, inplace=True)\n",
    "    return df_list\n",
    "\n",
    "# Removing unnecessary rows from list of dataframes:\n",
    "remove_mutual_unnecessary_columns(balance_list)\n",
    "remove_mutual_unnecessary_columns(pnl_list)\n",
    "\n",
    "# Renaming collumns to be the same across dataframes:\n",
    "def rename_columns(df_list):\n",
    "    for df in df_list:\n",
    "        # Rename 'obj_kodas' to 'ja_kodas' if it exists\n",
    "        if 'obj_kodas' in df.columns:\n",
    "            df.rename(columns={'obj_kodas': 'ja_kodas'}, inplace=True)\n",
    "\n",
    "        # Rename other columns if they exist\n",
    "        column_mapping = {\n",
    "            'nuosavas_kapitalas': 'NUOSAVAS KAPITALAS',\n",
    "            'mok_sumos_ir_isipareigojimai': 'MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI',\n",
    "            'trumpalaikis_turtas': 'TRUMPALAIKIS TURTAS',\n",
    "            'ilgalaikis_turtas': 'ILGALAIKIS TURTAS',\n",
    "            'pelnas_pries_apmokestinima': 'PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ',\n",
    "        'grynasis_pelnas': 'GRYNASIS PELNAS (NUOSTOLIAI)',\n",
    "        'pardavimo_pajamos': 'PARDAVIMO PAJAMOS'\n",
    "        }\n",
    "\n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in df.columns:\n",
    "                df.rename(columns={old_col: new_col}, inplace=True)\n",
    "\n",
    "    return df_list\n",
    "\n",
    "rename_columns(balance_list)\n",
    "rename_columns(pnl_list)\n",
    "\n",
    "\n"
   ],
   "id": "1327bddc3aa3498d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         ja_kodas  form_kodas  stat_kodas template_id standard_id  \\\n",
       " 0       110003978         310           0      FS0329      IST024   \n",
       " 1       110003978         310           0      FS0329      IST024   \n",
       " 2       110003978         310           0      FS0329      IST024   \n",
       " 3       110004884         310           0      FS0718      IST209   \n",
       " 4       110004884         310           0      FS0718      IST209   \n",
       " ...           ...         ...         ...         ...         ...   \n",
       " 423454  307123738         310           0      FS0329      IST024   \n",
       " 423455  307193537         960           0      FS0522      IST024   \n",
       " 423456  307193537         960           0      FS0522      IST024   \n",
       " 423457  307438075         960           0      FS0522      IST118   \n",
       " 423458  307438075         960           0      FS0522      IST118   \n",
       " \n",
       "                                       line_name  reiksme beginning_date  \\\n",
       " 0                             PARDAVIMO PAJAMOS    97545     2024-01-01   \n",
       " 1                  GRYNASIS PELNAS (NUOSTOLIAI)  2397510     2024-01-01   \n",
       " 2       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  2755467     2024-01-01   \n",
       " 3         ATASKAITINIŲ METŲ PELNAS (NUOSTOLIAI)   511543     2024-01-01   \n",
       " 4       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ   511543     2024-01-01   \n",
       " ...                                         ...      ...            ...   \n",
       " 423454  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ        0     2025-03-17   \n",
       " 423455             GRYNASIS PELNAS (NUOSTOLIAI)        0     2025-06-06   \n",
       " 423456  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ        0     2025-06-06   \n",
       " 423457             GRYNASIS PELNAS (NUOSTOLIAI)        0     2025-09-18   \n",
       " 423458  PELNAS (NUOSTOLIAI) PRIEš APMOKESTINIMą        0     2025-09-18   \n",
       " \n",
       "        turning_date    reg_date formavimo_data  \n",
       " 0        2024-12-31  2025-05-28     2025-11-03  \n",
       " 1        2024-12-31  2025-05-28     2025-11-03  \n",
       " 2        2024-12-31  2025-05-28     2025-11-03  \n",
       " 3        2024-12-31  2025-05-28     2025-11-03  \n",
       " 4        2024-12-31  2025-05-28     2025-11-03  \n",
       " ...             ...         ...            ...  \n",
       " 423454   2025-06-30  2025-10-31     2025-11-03  \n",
       " 423455   2025-07-22  2025-07-22     2025-11-03  \n",
       " 423456   2025-07-22  2025-07-22     2025-11-03  \n",
       " 423457   2025-10-22  2025-10-24     2025-11-03  \n",
       " 423458   2025-10-22  2025-10-24     2025-11-03  \n",
       " \n",
       " [423459 rows x 11 columns],\n",
       "          ja_kodas  form_kodas  stat_kodas template_id standard_id  \\\n",
       " 0       110003978         310           0      FS0229      IST024   \n",
       " 1       110003978         310           0      FS0229      IST024   \n",
       " 2       110003978         310           0      FS0229      IST024   \n",
       " 3       110004884         310           0      FS0618      IST209   \n",
       " 4       110004884         310           0      FS0618      IST209   \n",
       " ...           ...         ...         ...         ...         ...   \n",
       " 406750  306748060         960           7      FS0522      IST118   \n",
       " 406751  306748060         960           7      FS0522      IST118   \n",
       " 406752  306748060         960           7      FS0522      IST118   \n",
       " 406753  306815114         310           0      FS0229      IST024   \n",
       " 406754  306815114         310           0      FS0229      IST024   \n",
       " \n",
       "                                       line_name  reiksme beginning_date  \\\n",
       " 0       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ   -17980     2023-01-01   \n",
       " 1                  GRYNASIS PELNAS (NUOSTOLIAI)   -20409     2023-01-01   \n",
       " 2                             PARDAVIMO PAJAMOS    74824     2023-01-01   \n",
       " 3                             PARDAVIMO PAJAMOS  9701655     2023-01-01   \n",
       " 4       PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  2151794     2023-01-01   \n",
       " ...                                         ...      ...            ...   \n",
       " 406750                        PARDAVIMO PAJAMOS       72     2024-05-08   \n",
       " 406751             GRYNASIS PELNAS (NUOSTOLIAI)     -198     2024-05-08   \n",
       " 406752  PELNAS (NUOSTOLIAI) PRIEš APMOKESTINIMą     -198     2024-05-08   \n",
       " 406753  PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ    -2071     2024-06-03   \n",
       " 406754             GRYNASIS PELNAS (NUOSTOLIAI)    -2071     2024-06-03   \n",
       " \n",
       "        turning_date    reg_date formavimo_data  \n",
       " 0        2023-12-31  2024-05-23     2025-04-21  \n",
       " 1        2023-12-31  2024-05-23     2025-04-21  \n",
       " 2        2023-12-31  2024-05-23     2025-04-21  \n",
       " 3        2023-12-31  2024-06-03     2025-04-21  \n",
       " 4        2023-12-31  2024-06-03     2025-04-21  \n",
       " ...             ...         ...            ...  \n",
       " 406750   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406751   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406752   2024-12-11  2024-12-19     2025-04-21  \n",
       " 406753   2024-06-30  2024-11-29     2025-04-21  \n",
       " 406754   2024-06-30  2024-11-29     2025-04-21  \n",
       " \n",
       " [406755 rows x 11 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       110003978         310              2      FS0229      IST024   \n",
       " 1       110004884         310              0      FS0618      IST209   \n",
       " 2       110005648         310              0      FS0229      IST024   \n",
       " 3       110006892         310              0      FS0229      IST024   \n",
       " 4       110008377         310              0      FS0229      IST024   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 141939  306370963         310              0      FS0422      IST118   \n",
       " 141940  306372583         960             10      FS0422      IST118   \n",
       " 141941  306384240         310              0      FS0229      IST024   \n",
       " 141942  306453633         960              0      FS0422      IST118   \n",
       " 141943  306600492         960              0      FS0422      IST118   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2022-01-01      2022-12-31  2023-05-24   \n",
       " 1           2022-01-01      2022-12-31  2023-06-30   \n",
       " 2           2022-01-01      2022-12-31  2023-05-15   \n",
       " 3           2022-01-01      2022-12-31  2023-06-16   \n",
       " 4           2022-01-01      2022-12-31  2023-05-23   \n",
       " ...                ...             ...         ...   \n",
       " 141939      2023-08-01      2023-11-30  2023-12-20   \n",
       " 141940      2023-08-02      2023-11-06  2023-11-09   \n",
       " 141941      2023-08-21      2023-09-14  2023-09-21   \n",
       " 141942      2023-09-26      2023-12-31  2023-12-31   \n",
       " 141943      2023-10-24      2023-12-28  2023-12-28   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                       15420.0                       13104.0   \n",
       " 1                                     -824210.0                           NaN   \n",
       " 2                                       14067.0                       11944.0   \n",
       " 3                                       14149.0                       13441.0   \n",
       " 4                                      159064.0                      135027.0   \n",
       " ...                                         ...                           ...   \n",
       " 141939                                  12142.0                       12142.0   \n",
       " 141940                                      0.0                           0.0   \n",
       " 141941                                      0.0                           0.0   \n",
       " 141942                                      0.0                           0.0   \n",
       " 141943                                      0.0                           0.0   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                 65196.0     2024-10-03  \n",
       " 1               8359577.0     2024-10-03  \n",
       " 2               1010501.0     2024-10-03  \n",
       " 3                167873.0     2024-10-03  \n",
       " 4                537185.0     2024-10-03  \n",
       " ...                   ...            ...  \n",
       " 141939            59125.0     2024-10-03  \n",
       " 141940                NaN     2024-10-03  \n",
       " 141941                NaN     2024-10-03  \n",
       " 141942                0.0     2024-10-03  \n",
       " 141943                NaN     2024-10-03  \n",
       " \n",
       " [141944 rows x 12 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       301011561         310              0      FS0129      IST024   \n",
       " 1       303641352         310              0      FS0129      IST024   \n",
       " 2       301684796         310              0      FS0128      IST023   \n",
       " 3       302502531         310              0      FS0129      IST024   \n",
       " 4       304590697         310              0      FS0129      IST024   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 123685  305189141         310              0      FS0129      IST024   \n",
       " 123686  304922605         960              0      FS0322      IST118   \n",
       " 123687  125935881         310              0      FS0129      IST024   \n",
       " 123688  300629576         310              0      FS0129      IST024   \n",
       " 123689  301507365         310              0      FS0129      IST024   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2021-01-01      2021-12-31  2022-01-02   \n",
       " 1           2021-01-01      2021-12-31  2022-05-27   \n",
       " 2           2021-01-01      2021-12-31  2022-06-29   \n",
       " 3           2021-01-01      2021-12-31  2022-05-30   \n",
       " 4           2021-01-01      2021-12-31  2022-04-21   \n",
       " ...                ...             ...         ...   \n",
       " 123685      2019-06-14      2019-12-31  2022-11-17   \n",
       " 123686      2021-01-01      2021-12-31  2022-02-25   \n",
       " 123687      2018-01-01      2018-12-31  2022-12-12   \n",
       " 123688      2021-01-01      2021-12-31  2022-06-23   \n",
       " 123689      2021-01-01      2021-12-31  2022-05-10   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                         -91.0                         -91.0   \n",
       " 1                                           0.0                           0.0   \n",
       " 2                                           NaN                           0.0   \n",
       " 3                                       20107.0                       18647.0   \n",
       " 4                                       78141.0                       74162.0   \n",
       " ...                                         ...                           ...   \n",
       " 123685                                      0.0                           0.0   \n",
       " 123686                                    461.0                         435.0   \n",
       " 123687                                      0.0                           0.0   \n",
       " 123688                                  79761.0                       67797.0   \n",
       " 123689                                  75692.0                       63564.0   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                     NaN     2023-03-01  \n",
       " 1                     NaN     2023-03-01  \n",
       " 2                     0.0     2023-03-01  \n",
       " 3               2163507.0     2023-03-01  \n",
       " 4                242465.0     2023-03-01  \n",
       " ...                   ...            ...  \n",
       " 123685                NaN     2023-03-01  \n",
       " 123686            44632.0     2023-03-01  \n",
       " 123687                NaN     2023-03-01  \n",
       " 123688          1733418.0     2023-03-01  \n",
       " 123689          4485193.0     2023-03-01  \n",
       " \n",
       " [123690 rows x 12 columns],\n",
       "          ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0       305390322         310              0      FS0128      IST023   \n",
       " 1       305213076         310              0      FS0128      IST023   \n",
       " 2       304088367         960              0      FS0322      IST118   \n",
       " 3       300094102         310              0      FS0129      IST024   \n",
       " 4       303219212         960              0      FS0322      IST118   \n",
       " ...           ...         ...            ...         ...         ...   \n",
       " 110220  302686921         310              1      FS0128      IST023   \n",
       " 110221  303289125         310              7      FS0128      IST023   \n",
       " 110222  305333912         310              0      FS0129      IST024   \n",
       " 110223  304150413         310              0      FS0129      IST024   \n",
       " 110224  303226623         630              0      FS0323      IST117   \n",
       " \n",
       "        laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0           2019-12-11      2019-12-31  2021-05-27   \n",
       " 1           2019-07-18      2019-12-31  2021-09-08   \n",
       " 2           2020-01-01      2020-12-31  2021-03-31   \n",
       " 3           2020-01-01      2020-12-31  2021-06-10   \n",
       " 4           2020-01-01      2020-12-31  2021-07-12   \n",
       " ...                ...             ...         ...   \n",
       " 110220      2020-01-01      2020-12-31  2021-05-26   \n",
       " 110221      2020-01-01      2020-12-31  2021-03-30   \n",
       " 110222      2020-01-01      2020-12-31  2021-07-11   \n",
       " 110223      2020-01-01      2020-12-31  2021-05-31   \n",
       " 110224      2020-01-01      2020-12-31  2021-05-25   \n",
       " \n",
       "         PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                           NaN                           0.0   \n",
       " 1                                           NaN                       -8042.0   \n",
       " 2                                       20624.0                       19562.0   \n",
       " 3                                       72425.0                       70062.0   \n",
       " 4                                           0.0                           0.0   \n",
       " ...                                         ...                           ...   \n",
       " 110220                                      NaN                      -61659.0   \n",
       " 110221                                      NaN                           0.0   \n",
       " 110222                                  20903.0                       19881.0   \n",
       " 110223                                 -10215.0                      -10215.0   \n",
       " 110224                                      NaN                           NaN   \n",
       " \n",
       "         PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0                     NaN     2023-03-01  \n",
       " 1                     NaN     2023-03-01  \n",
       " 2                 43780.0     2023-03-01  \n",
       " 3                155482.0     2023-03-01  \n",
       " 4                     NaN     2023-03-01  \n",
       " ...                   ...            ...  \n",
       " 110220           584174.0     2023-03-01  \n",
       " 110221                0.0     2023-03-01  \n",
       " 110222           142964.0     2023-03-01  \n",
       " 110223            97068.0     2023-03-01  \n",
       " 110224              376.0     2023-03-01  \n",
       " \n",
       " [110225 rows x 12 columns],\n",
       "         ja_kodas  form_kodas  stat_statusas template_id standard_id  \\\n",
       " 0      304406916         310              0      FS0129      IST024   \n",
       " 1      304064380         310              0      FS0128      IST023   \n",
       " 2      305186985         960              0      FS0322      IST118   \n",
       " 3      302915341         310              0      FS0129      IST024   \n",
       " 4      300846448         310              0      FS0129      IST024   \n",
       " ...          ...         ...            ...         ...         ...   \n",
       " 96610  302797423         310              0      FS0128      IST023   \n",
       " 96611  133553116         310              0      FS0128      IST023   \n",
       " 96612  304074296         310              0      FS0128      IST023   \n",
       " 96613  303199069         310              0      FS0129      IST024   \n",
       " 96614  302478692         310              0      FS0128      IST023   \n",
       " \n",
       "       laikotarpis_nuo laikotarpis_iki    reg_date  \\\n",
       " 0          2019-01-01      2019-12-31  2020-04-30   \n",
       " 1          2018-01-01      2018-12-31  2020-06-14   \n",
       " 2          2019-06-10      2019-12-31  2020-06-10   \n",
       " 3          2019-01-01      2019-12-31  2020-10-01   \n",
       " 4          2018-01-01      2018-12-31  2020-12-29   \n",
       " ...               ...             ...         ...   \n",
       " 96610      2018-01-01      2018-12-31  2020-05-04   \n",
       " 96611      2017-01-01      2017-12-31  2020-02-20   \n",
       " 96612      2019-01-01      2019-12-31  2020-05-14   \n",
       " 96613      2019-01-01      2019-12-31  2020-05-30   \n",
       " 96614      2019-01-01      2019-12-31  2020-05-19   \n",
       " \n",
       "        PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ  GRYNASIS PELNAS (NUOSTOLIAI)  \\\n",
       " 0                                     119356.0                      113384.0   \n",
       " 1                                          NaN                         479.0   \n",
       " 2                                          0.0                           0.0   \n",
       " 3                                      -2748.0                       -2748.0   \n",
       " 4                                          0.0                           0.0   \n",
       " ...                                        ...                           ...   \n",
       " 96610                                      NaN                        3252.0   \n",
       " 96611                                      NaN                        3621.0   \n",
       " 96612                                      NaN                        -318.0   \n",
       " 96613                                  72867.0                       69224.0   \n",
       " 96614                                      NaN                         218.0   \n",
       " \n",
       "        PARDAVIMO PAJAMOS formavimo_data  \n",
       " 0               182596.0     2023-03-01  \n",
       " 1                17406.0     2023-03-01  \n",
       " 2                    NaN     2023-03-01  \n",
       " 3               170934.0     2023-03-01  \n",
       " 4                    NaN     2023-03-01  \n",
       " ...                  ...            ...  \n",
       " 96610           233772.0     2023-03-01  \n",
       " 96611            10580.0     2023-03-01  \n",
       " 96612                0.0     2023-03-01  \n",
       " 96613            75500.0     2023-03-01  \n",
       " 96614           478292.0     2023-03-01  \n",
       " \n",
       " [96615 rows x 12 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Extracting columns line_name, reiksme and ja_kodas:\n",
    "This function is uneeded but if you need to view just the extracted columns, you can use it:"
   ],
   "id": "122c2fd83cc6d48c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:14.939942Z",
     "start_time": "2025-11-10T21:20:14.919015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extracting columns line_name, reiksme and ja_kodas from dfs with all of this data:\n",
    "def extract_line_name_reiksme_ja_kodas(df_list):\n",
    "    \"\"\"\n",
    "    Extract columns 'line_name', 'reiksme', and 'ja_kodas' from DataFrames\n",
    "    that contain all three columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of pandas.DataFrame\n",
    "        List of DataFrames to process (will be modified in-place)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of pandas.DataFrame\n",
    "        List of DataFrames containing only the three specified columns\n",
    "    \"\"\"\n",
    "    extracted_dfs = []\n",
    "\n",
    "    required_columns = ['line_name', 'reiksme', 'ja_kodas']\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        # Check if all required columns exist in the current DataFrame\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            # Extract only the required columns\n",
    "            extracted_df = df[required_columns].copy()\n",
    "            extracted_dfs.append(extracted_df)\n",
    "\n",
    "\n",
    "        else:\n",
    "            missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "            print(f\"DataFrame {i}: Missing columns {missing_cols} - skipped\")\n",
    "\n",
    "    print(f\"\\nExtracted {len(extracted_dfs)} out of {len(df_list)} DataFrames\")\n",
    "    return extracted_dfs\n",
    "\n",
    "B_extracted = extract_line_name_reiksme_ja_kodas(balance_list)\n",
    "P_extracted = extract_line_name_reiksme_ja_kodas(pnl_list)\n",
    "\n",
    "# Renaming the extracted dfs to be more descriptive:\n",
    "B_extracted_2025 = B_extracted[0]\n",
    "B_extracted_2024 = B_extracted[1]\n",
    "\n",
    "P_extracted_2025 = P_extracted[0]\n",
    "P_extracted_2024 = P_extracted[1]\n",
    "\n",
    "# New lists with extracted and renamed dfs:\n",
    "B_extracted_renamed = [B_extracted_2025, B_extracted_2024]\n",
    "P_extracted_renamed = [P_extracted_2025, P_extracted_2024]"
   ],
   "id": "d82b4bb6516b5786",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 2: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "\n",
      "Extracted 2 out of 6 DataFrames\n",
      "DataFrame 2: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme'] - skipped\n",
      "\n",
      "Extracted 2 out of 6 DataFrames\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Shifting the column data of extraced dfs so that every row is unique with new columns:",
   "id": "8c0ff99de1a50176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:16.643245Z",
     "start_time": "2025-11-10T21:20:14.977915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shifting the column data of extraced dfs so that every row is unique:\n",
    "def pivot_dfs(df_list, aggfunc='first'):\n",
    "    \"\"\"\n",
    "    Apply pivot transformation to multiple DataFrames with many columns.\n",
    "    Only uses 'line_name', 'reiksme', 'ja_kodas' for pivoting, ignores other columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of pandas.DataFrame\n",
    "        List of DataFrames to pivot (can have many additional columns)\n",
    "    aggfunc : str or function, default 'first'\n",
    "        Aggregation function for duplicates\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of pandas.DataFrame\n",
    "        List of pivoted DataFrames\n",
    "    \"\"\"\n",
    "\n",
    "    def pivot_line_names_to_columns(df, aggfunc='first'):\n",
    "        \"\"\"\n",
    "        Pivot using only the three required columns, ignoring all others.\n",
    "        \"\"\"\n",
    "        # Select only the columns needed for pivoting\n",
    "        pivot_data = df[['ja_kodas', 'line_name', 'reiksme']].copy()\n",
    "\n",
    "        # Pivot the table\n",
    "        pivoted_df = pivot_data.pivot_table(\n",
    "            index='ja_kodas',\n",
    "            columns='line_name',\n",
    "            values='reiksme',\n",
    "            aggfunc=aggfunc\n",
    "        ).reset_index()\n",
    "\n",
    "        # Reset column names and clean up the DataFrame\n",
    "        pivoted_df.columns.name = None\n",
    "\n",
    "        return pivoted_df\n",
    "\n",
    "    pivoted_dfs = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            # Check if required columns exist\n",
    "            required_columns = ['line_name', 'reiksme', 'ja_kodas']\n",
    "            if not all(col in df.columns for col in required_columns):\n",
    "                missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "                print(f\"DataFrame {i}: Missing columns {missing_cols}. Available: {list(df.columns)}\")\n",
    "                pivoted_dfs.append(df)\n",
    "                continue\n",
    "\n",
    "            # Show info about the DataFrame\n",
    "            print(f\"DataFrame {i}: Original columns: {len(df.columns)}\")\n",
    "            print(f\"DataFrame {i}: Using 3 columns for pivoting, ignoring {len(df.columns) - 3} other columns\")\n",
    "            print(f\"DataFrame {i}: Unique line_name values: {df['line_name'].nunique()}\")\n",
    "            print(f\"DataFrame {i}: Unique ja_kodas values: {df['ja_kodas'].nunique()}\")\n",
    "\n",
    "            # Perform pivot (only uses the 3 required columns)\n",
    "            pivoted_df = pivot_line_names_to_columns(df, aggfunc)\n",
    "            pivoted_dfs.append(pivoted_df)\n",
    "            print(f\"DataFrame {i}: Successfully pivoted. Original shape: {df.shape}, Pivoted shape: {pivoted_df.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"DataFrame {i}: Error during pivoting - {e}\")\n",
    "            pivoted_dfs.append(df)\n",
    "\n",
    "    return pivoted_dfs\n",
    "\n",
    "pivot_dfs(B_extracted_renamed)\n",
    "pivot_dfs(P_extracted_renamed)\n",
    "\n",
    "# Renaming the pivoted dfs to be more descriptive:\n",
    "B_pivoted_2025 = pivot_dfs(B_extracted_renamed)[0]\n",
    "B_pivoted_2024 = pivot_dfs(B_extracted_renamed)[1]\n",
    "\n",
    "P_pivoted_2025 = pivot_dfs(P_extracted_renamed)[0]\n",
    "P_pivoted_2024 = pivot_dfs(P_extracted_renamed)[1]\n",
    "\n",
    "# Saving in lists:\n",
    "B_pivoted = pivot_dfs(B_extracted_renamed)\n",
    "P_pivoted = pivot_dfs(P_extracted_renamed)"
   ],
   "id": "6828db32ded46bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 9\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 3), Pivoted shape: (146512, 10)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 9\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 3), Pivoted shape: (141315, 10)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 8\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 3), Pivoted shape: (146512, 9)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 8\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 3), Pivoted shape: (141315, 9)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 9\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 3), Pivoted shape: (146512, 10)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 9\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 3), Pivoted shape: (141315, 10)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 9\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 3), Pivoted shape: (146512, 10)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 9\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 3), Pivoted shape: (141315, 10)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 8\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 3), Pivoted shape: (146512, 9)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 8\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 3), Pivoted shape: (141315, 9)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 8\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 3), Pivoted shape: (146512, 9)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 8\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 3), Pivoted shape: (141315, 9)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 9\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 3), Pivoted shape: (146512, 10)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 9\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 3), Pivoted shape: (141315, 10)\n",
      "DataFrame 0: Original columns: 3\n",
      "DataFrame 0: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 0: Unique line_name values: 8\n",
      "DataFrame 0: Unique ja_kodas values: 146512\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 3), Pivoted shape: (146512, 9)\n",
      "DataFrame 1: Original columns: 3\n",
      "DataFrame 1: Using 3 columns for pivoting, ignoring 0 other columns\n",
      "DataFrame 1: Unique line_name values: 8\n",
      "DataFrame 1: Unique ja_kodas values: 141315\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 3), Pivoted shape: (141315, 9)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:17.725288Z",
     "start_time": "2025-11-10T21:20:16.762095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pivoting the big dataframes:\n",
    "def pivot_dfs_smart(df_list):\n",
    "    \"\"\"\n",
    "    Apply pivot transformation with smart aggregation for different column types.\n",
    "    \"\"\"\n",
    "\n",
    "    def pivot_line_names_to_columns_smart(df):\n",
    "        \"\"\"\n",
    "        Pivot with intelligent aggregation based on column data types.\n",
    "        \"\"\"\n",
    "        # Identify column types for smart aggregation\n",
    "        numeric_columns = []\n",
    "        string_columns = []\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col in ['line_name', 'reiksme']:\n",
    "                continue\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                numeric_columns.append(col)\n",
    "            else:\n",
    "                string_columns.append(col)\n",
    "\n",
    "        # Create aggregation dictionary\n",
    "        aggregation_dict = {'reiksme': 'first'}\n",
    "\n",
    "        # For numeric columns, use 'first' or 'mean' depending on context\n",
    "        for col in numeric_columns:\n",
    "            aggregation_dict[col] = 'first'\n",
    "\n",
    "        # For string columns, use 'first' (take the first occurrence)\n",
    "        for col in string_columns:\n",
    "            aggregation_dict[col] = 'first'\n",
    "\n",
    "        # Identify index columns (all columns except line_name and reiksme)\n",
    "        index_columns = [col for col in df.columns if col not in ['line_name', 'reiksme']]\n",
    "\n",
    "        # Perform pivot\n",
    "        pivoted_df = df.pivot_table(\n",
    "            index=index_columns,\n",
    "            columns='line_name',\n",
    "            values='reiksme',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "\n",
    "        # Reset column names\n",
    "        pivoted_df.columns.name = None\n",
    "\n",
    "        return pivoted_df\n",
    "\n",
    "    pivoted_dfs = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            required_columns = ['line_name', 'reiksme', 'ja_kodas']\n",
    "            if not all(col in df.columns for col in required_columns):\n",
    "                missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "                print(f\"DataFrame {i}: Missing columns {missing_cols}\")\n",
    "                pivoted_dfs.append(df)\n",
    "                continue\n",
    "\n",
    "            print(f\"DataFrame {i}: Preserving {len(df.columns) - 2} columns in result\")\n",
    "\n",
    "            pivoted_df = pivot_line_names_to_columns_smart(df)\n",
    "            pivoted_dfs.append(pivoted_df)\n",
    "            print(f\"DataFrame {i}: Successfully pivoted. Original shape: {df.shape}, Pivoted shape: {pivoted_df.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"DataFrame {i}: Error during pivoting - {e}\")\n",
    "            pivoted_dfs.append(df)\n",
    "\n",
    "    return pivoted_dfs\n",
    "\n",
    "# Balance data:\n",
    "finalB = pivot_dfs_smart(balance_list)\n",
    "# PnL data:\n",
    "finalP = pivot_dfs_smart(pnl_list)\n",
    "\n",
    "# Renaming the final dfs to be more descriptive:\n",
    "finalB2025 = finalB[0]\n",
    "finalB2024 = finalB[1]\n",
    "\n",
    "finalP2025 = finalP[0]\n",
    "finalP2024 = finalP[1]\n",
    "\n"
   ],
   "id": "84da8781880eccc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Preserving 9 columns in result\n",
      "DataFrame 0: Successfully pivoted. Original shape: (615188, 11), Pivoted shape: (156318, 18)\n",
      "DataFrame 1: Preserving 9 columns in result\n",
      "DataFrame 1: Successfully pivoted. Original shape: (604271, 11), Pivoted shape: (153607, 18)\n",
      "DataFrame 2: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 0: Preserving 9 columns in result\n",
      "DataFrame 0: Successfully pivoted. Original shape: (423459, 11), Pivoted shape: (156318, 17)\n",
      "DataFrame 1: Preserving 9 columns in result\n",
      "DataFrame 1: Successfully pivoted. Original shape: (406755, 11), Pivoted shape: (153607, 17)\n",
      "DataFrame 2: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 3: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 4: Missing columns ['line_name', 'reiksme']\n",
      "DataFrame 5: Missing columns ['line_name', 'reiksme']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "16836003988cd0b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adding PnL data to balance data:",
   "id": "73ebb67616413f32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:19.077488Z",
     "start_time": "2025-11-10T21:20:17.842276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding PnL data to balance data:\n",
    "\n",
    "def merge_pnl_and_balances(df_list1, df_list2, how='inner'):\n",
    "    \"\"\"\n",
    "    Merge two lists of DataFrames on ja_kodas column with comprehensive diagnostics and validation.\n",
    "    Each DataFrame from list1 is merged with corresponding DataFrame from list2.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list1, df_list2 : list of pandas.DataFrame\n",
    "        Lists of DataFrames to merge\n",
    "    how : str, default 'inner'\n",
    "        Type of merge: 'inner', 'left', 'right', 'outer'\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of pandas.DataFrame\n",
    "        List of merged DataFrames\n",
    "    \"\"\"\n",
    "    if len(df_list1) != len(df_list2):\n",
    "        print(f\"Warning: List lengths differ - list1: {len(df_list1)}, list2: {len(df_list2)}\")\n",
    "        # Use the minimum length to avoid index errors\n",
    "        min_length = min(len(df_list1), len(df_list2))\n",
    "        df_list1 = df_list1[:min_length]\n",
    "        df_list2 = df_list2[:min_length]\n",
    "\n",
    "    merged_dfs = []\n",
    "\n",
    "    for i, (df1, df2) in enumerate(zip(df_list1, df_list2)):\n",
    "        try:\n",
    "            # Check if ja_kodas exists in both DataFrames\n",
    "            if 'ja_kodas' not in df1.columns:\n",
    "                print(f\"Pair {i}: ja_kodas not found in first DataFrame, skipping\")\n",
    "                continue\n",
    "            if 'ja_kodas' not in df2.columns:\n",
    "                print(f\"Pair {i}: ja_kodas not found in second DataFrame, skipping\")\n",
    "                continue\n",
    "\n",
    "            # Create copies to avoid modifying originals\n",
    "            df1_clean = df1.copy()\n",
    "            df2_clean = df2.copy()\n",
    "\n",
    "            # Validate ja_kodas data types and convert if necessary\n",
    "            if df1_clean['ja_kodas'].dtype != df2_clean['ja_kodas'].dtype:\n",
    "                print(f\"Pair {i}: ja_kodas data types differ - converting both to string\")\n",
    "                df1_clean['ja_kodas'] = df1_clean['ja_kodas'].astype(str)\n",
    "                df2_clean['ja_kodas'] = df2_clean['ja_kodas'].astype(str)\n",
    "\n",
    "            # Check for duplicate ja_kodas within each DataFrame\n",
    "            df1_duplicates = df1_clean.duplicated(subset=['ja_kodas']).sum()\n",
    "            df2_duplicates = df2_clean.duplicated(subset=['ja_kodas']).sum()\n",
    "\n",
    "            if df1_duplicates > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df1_duplicates} duplicate ja_kodas found in first DataFrame\")\n",
    "                # Keep first occurrence of duplicates\n",
    "                df1_clean = df1_clean.drop_duplicates(subset=['ja_kodas'], keep='first')\n",
    "\n",
    "            if df2_duplicates > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df2_duplicates} duplicate ja_kodas found in second DataFrame\")\n",
    "                # Keep first occurrence of duplicates\n",
    "                df2_clean = df2_clean.drop_duplicates(subset=['ja_kodas'], keep='first')\n",
    "\n",
    "            # Check for NaN values in ja_kodas\n",
    "            df1_nan = df1_clean['ja_kodas'].isna().sum()\n",
    "            df2_nan = df2_clean['ja_kodas'].isna().sum()\n",
    "\n",
    "            if df1_nan > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df1_nan} NaN values in ja_kodas (first DataFrame), removing\")\n",
    "                df1_clean = df1_clean.dropna(subset=['ja_kodas'])\n",
    "\n",
    "            if df2_nan > 0:\n",
    "                print(f\"Pair {i}: WARNING - {df2_nan} NaN values in ja_kodas (second DataFrame), removing\")\n",
    "                df2_clean = df2_clean.dropna(subset=['ja_kodas'])\n",
    "\n",
    "            # Pre-merge diagnostics\n",
    "            df1_unique = df1_clean['ja_kodas'].nunique()\n",
    "            df2_unique = df2_clean['ja_kodas'].nunique()\n",
    "            common_ja_kodas = set(df1_clean['ja_kodas']) & set(df2_clean['ja_kodas'])\n",
    "            common_count = len(common_ja_kodas)\n",
    "\n",
    "            print(f\"\\n--- Pair {i} Merge Diagnostics ---\")\n",
    "            print(f\"DF1: {len(df1_clean)} rows, {df1_unique} unique ja_kodas\")\n",
    "            print(f\"DF2: {len(df2_clean)} rows, {df2_unique} unique ja_kodas\")\n",
    "            print(f\"Common ja_kodas: {common_count}\")\n",
    "            print(f\"Merge type: {how}\")\n",
    "\n",
    "            # Calculate expected result sizes\n",
    "            if how == 'inner':\n",
    "                expected_rows = common_count\n",
    "            elif how == 'left':\n",
    "                expected_rows = len(df1_clean)\n",
    "            elif how == 'right':\n",
    "                expected_rows = len(df2_clean)\n",
    "            else:  # outer\n",
    "                expected_rows = len(df1_clean) + len(df2_clean) - common_count\n",
    "\n",
    "            print(f\"Expected result rows: {expected_rows}\")\n",
    "\n",
    "            # Perform the merge with indicator to track sources\n",
    "            merged_df = pd.merge(\n",
    "                df1_clean,\n",
    "                df2_clean,\n",
    "                on='ja_kodas',\n",
    "                how=how,\n",
    "                suffixes=('_pnl', '_balance'),\n",
    "                indicator=True  # Add merge indicator column\n",
    "            )\n",
    "\n",
    "            # Post-merge diagnostics\n",
    "            actual_rows = len(merged_df)\n",
    "            merge_stats = merged_df['_merge'].value_counts()\n",
    "\n",
    "            print(f\"Actual result rows: {actual_rows}\")\n",
    "            print(f\"Merge composition: {merge_stats.to_dict()}\")\n",
    "\n",
    "            if actual_rows != expected_rows:\n",
    "                print(f\"WARNING: Expected {expected_rows} rows but got {actual_rows} rows\")\n",
    "\n",
    "            # Remove the indicator column\n",
    "            merged_df = merged_df.drop('_merge', axis=1)\n",
    "\n",
    "            # Check for overlapping column names (besides ja_kodas)\n",
    "            overlapping_cols = set(df1_clean.columns) & set(df2_clean.columns) - {'ja_kodas'}\n",
    "            if overlapping_cols:\n",
    "                print(f\"Overlapping columns (received suffixes): {list(overlapping_cols)}\")\n",
    "\n",
    "            print(f\"Pair {i}: Successfully merged. Shapes: {df1.shape} + {df2.shape} -> {merged_df.shape}\")\n",
    "\n",
    "            merged_dfs.append(merged_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Pair {i}: Error during merge - {e}\")\n",
    "            print(f\"Pair {i}: DF1 columns: {list(df1.columns) if 'df1' in locals() else 'N/A'}\")\n",
    "            print(f\"Pair {i}: DF2 columns: {list(df2.columns) if 'df2' in locals() else 'N/A'}\")\n",
    "            # Keep both original DataFrames if merge fails\n",
    "            merged_dfs.extend([df1, df2])\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\n=== MERGE SUMMARY ===\")\n",
    "    print(f\"Successfully processed: {len(merged_dfs)} DataFrames\")\n",
    "    print(f\"Total input pairs: {min(len(df_list1), len(df_list2))}\")\n",
    "\n",
    "    return merged_dfs\n",
    "# Joining all the dfs:\n",
    "joined_BP_list = merge_pnl_and_balances(finalB, finalP, how='inner')\n",
    "\n",
    "# Renaming the joined dfs to be more descriptive:\n",
    "joined_BP2025 = joined_BP_list[0]\n",
    "joined_BP2024 = joined_BP_list[1]\n",
    "joined_BP2023 = joined_BP_list[2]\n",
    "joined_BP2022 = joined_BP_list[3]\n",
    "joined_BP2021 = joined_BP_list[4]\n",
    "joined_BP2020 = joined_BP_list[5]\n",
    "\n",
    "# Joining all the dfs and keeping all unmatched rows:\n",
    "joined_BP_all_list = merge_pnl_and_balances(finalB, finalP, how='outer')\n",
    "\n",
    "# Renaming the joined dfs to be more descriptive:\n",
    "joined_BP_all2025 = joined_BP_all_list[0]\n",
    "joined_BP_all2024 = joined_BP_all_list[1]\n",
    "joined_BP_all2023 = joined_BP_all_list[2]\n",
    "joined_BP_all2022 = joined_BP_all_list[3]\n",
    "joined_BP_all2021 = joined_BP_all_list[4]\n",
    "joined_BP_all2020 = joined_BP_all_list[5]\n"
   ],
   "id": "7373f173f1380777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 0: WARNING - 9806 duplicate ja_kodas found in first DataFrame\n",
      "Pair 0: WARNING - 9806 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 146512 rows, 146512 unique ja_kodas\n",
      "DF2: 146512 rows, 146512 unique ja_kodas\n",
      "Common ja_kodas: 146512\n",
      "Merge type: inner\n",
      "Expected result rows: 146512\n",
      "Actual result rows: 146512\n",
      "Merge composition: {'both': 146512, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'stat_kodas', 'formavimo_data', 'standard_id', 'turning_date', 'beginning_date', 'reg_date', 'form_kodas']\n",
      "Pair 0: Successfully merged. Shapes: (156318, 18) + (156318, 17) -> (146512, 34)\n",
      "Pair 1: WARNING - 12292 duplicate ja_kodas found in first DataFrame\n",
      "Pair 1: WARNING - 12292 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 141315 rows, 141315 unique ja_kodas\n",
      "DF2: 141315 rows, 141315 unique ja_kodas\n",
      "Common ja_kodas: 141315\n",
      "Merge type: inner\n",
      "Expected result rows: 141315\n",
      "Actual result rows: 141315\n",
      "Merge composition: {'both': 141315, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'stat_kodas', 'formavimo_data', 'standard_id', 'turning_date', 'beginning_date', 'reg_date', 'form_kodas']\n",
      "Pair 1: Successfully merged. Shapes: (153607, 18) + (153607, 17) -> (141315, 34)\n",
      "Pair 2: WARNING - 152850 duplicate ja_kodas found in first DataFrame\n",
      "Pair 2: WARNING - 22447 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 151619 rows, 151619 unique ja_kodas\n",
      "DF2: 119497 rows, 119497 unique ja_kodas\n",
      "Common ja_kodas: 119497\n",
      "Merge type: inner\n",
      "Expected result rows: 119497\n",
      "Actual result rows: 119497\n",
      "Merge composition: {'both': 119497, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 2: Successfully merged. Shapes: (304469, 13) + (141944, 12) -> (119497, 24)\n",
      "Pair 3: WARNING - 21325 duplicate ja_kodas found in first DataFrame\n",
      "Pair 3: WARNING - 16083 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 119072 rows, 119072 unique ja_kodas\n",
      "DF2: 107607 rows, 107607 unique ja_kodas\n",
      "Common ja_kodas: 107607\n",
      "Merge type: inner\n",
      "Expected result rows: 107607\n",
      "Actual result rows: 107607\n",
      "Merge composition: {'both': 107607, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 3: Successfully merged. Shapes: (140397, 13) + (123690, 12) -> (107607, 24)\n",
      "Pair 4: WARNING - 14073 duplicate ja_kodas found in first DataFrame\n",
      "Pair 4: WARNING - 12261 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 106775 rows, 106775 unique ja_kodas\n",
      "DF2: 97964 rows, 97964 unique ja_kodas\n",
      "Common ja_kodas: 97964\n",
      "Merge type: inner\n",
      "Expected result rows: 97964\n",
      "Actual result rows: 97964\n",
      "Merge composition: {'both': 97964, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 4: Successfully merged. Shapes: (120848, 13) + (110225, 12) -> (97964, 24)\n",
      "Pair 5: WARNING - 9965 duplicate ja_kodas found in first DataFrame\n",
      "Pair 5: WARNING - 8383 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 96352 rows, 96352 unique ja_kodas\n",
      "DF2: 88232 rows, 88232 unique ja_kodas\n",
      "Common ja_kodas: 88232\n",
      "Merge type: inner\n",
      "Expected result rows: 88232\n",
      "Actual result rows: 88232\n",
      "Merge composition: {'both': 88232, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 5: Successfully merged. Shapes: (106317, 13) + (96615, 12) -> (88232, 24)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "Successfully processed: 6 DataFrames\n",
      "Total input pairs: 6\n",
      "Pair 0: WARNING - 9806 duplicate ja_kodas found in first DataFrame\n",
      "Pair 0: WARNING - 9806 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 146512 rows, 146512 unique ja_kodas\n",
      "DF2: 146512 rows, 146512 unique ja_kodas\n",
      "Common ja_kodas: 146512\n",
      "Merge type: outer\n",
      "Expected result rows: 146512\n",
      "Actual result rows: 146512\n",
      "Merge composition: {'both': 146512, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'stat_kodas', 'formavimo_data', 'standard_id', 'turning_date', 'beginning_date', 'reg_date', 'form_kodas']\n",
      "Pair 0: Successfully merged. Shapes: (156318, 18) + (156318, 17) -> (146512, 34)\n",
      "Pair 1: WARNING - 12292 duplicate ja_kodas found in first DataFrame\n",
      "Pair 1: WARNING - 12292 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 141315 rows, 141315 unique ja_kodas\n",
      "DF2: 141315 rows, 141315 unique ja_kodas\n",
      "Common ja_kodas: 141315\n",
      "Merge type: outer\n",
      "Expected result rows: 141315\n",
      "Actual result rows: 141315\n",
      "Merge composition: {'both': 141315, 'left_only': 0, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'stat_kodas', 'formavimo_data', 'standard_id', 'turning_date', 'beginning_date', 'reg_date', 'form_kodas']\n",
      "Pair 1: Successfully merged. Shapes: (153607, 18) + (153607, 17) -> (141315, 34)\n",
      "Pair 2: WARNING - 152850 duplicate ja_kodas found in first DataFrame\n",
      "Pair 2: WARNING - 22447 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 151619 rows, 151619 unique ja_kodas\n",
      "DF2: 119497 rows, 119497 unique ja_kodas\n",
      "Common ja_kodas: 119497\n",
      "Merge type: outer\n",
      "Expected result rows: 151619\n",
      "Actual result rows: 151619\n",
      "Merge composition: {'both': 119497, 'left_only': 32122, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 2: Successfully merged. Shapes: (304469, 13) + (141944, 12) -> (151619, 24)\n",
      "Pair 3: WARNING - 21325 duplicate ja_kodas found in first DataFrame\n",
      "Pair 3: WARNING - 16083 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 119072 rows, 119072 unique ja_kodas\n",
      "DF2: 107607 rows, 107607 unique ja_kodas\n",
      "Common ja_kodas: 107607\n",
      "Merge type: outer\n",
      "Expected result rows: 119072\n",
      "Actual result rows: 119072\n",
      "Merge composition: {'both': 107607, 'left_only': 11465, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 3: Successfully merged. Shapes: (140397, 13) + (123690, 12) -> (119072, 24)\n",
      "Pair 4: WARNING - 14073 duplicate ja_kodas found in first DataFrame\n",
      "Pair 4: WARNING - 12261 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 106775 rows, 106775 unique ja_kodas\n",
      "DF2: 97964 rows, 97964 unique ja_kodas\n",
      "Common ja_kodas: 97964\n",
      "Merge type: outer\n",
      "Expected result rows: 106775\n",
      "Actual result rows: 106775\n",
      "Merge composition: {'both': 97964, 'left_only': 8811, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 4: Successfully merged. Shapes: (120848, 13) + (110225, 12) -> (106775, 24)\n",
      "Pair 5: WARNING - 9965 duplicate ja_kodas found in first DataFrame\n",
      "Pair 5: WARNING - 8383 duplicate ja_kodas found in second DataFrame\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 96352 rows, 96352 unique ja_kodas\n",
      "DF2: 88232 rows, 88232 unique ja_kodas\n",
      "Common ja_kodas: 88232\n",
      "Merge type: outer\n",
      "Expected result rows: 96352\n",
      "Actual result rows: 96352\n",
      "Merge composition: {'both': 88232, 'left_only': 8120, 'right_only': 0}\n",
      "Overlapping columns (received suffixes): ['template_id', 'laikotarpis_iki', 'stat_statusas', 'formavimo_data', 'laikotarpis_nuo', 'standard_id', 'reg_date', 'form_kodas']\n",
      "Pair 5: Successfully merged. Shapes: (106317, 13) + (96615, 12) -> (96352, 24)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "Successfully processed: 6 DataFrames\n",
      "Total input pairs: 6\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### File is getting long, so lets save the final dataframes to csv files and move to other notebooks where we will do some data analysis, create new variables:",
   "id": "539aec65de341fcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:20:19.199259Z",
     "start_time": "2025-11-10T21:20:19.197931Z"
    }
   },
   "cell_type": "code",
   "source": "### Notebook is gettig long, so lets save the final dataframes to csv files and move to other notebooks where we will do some data analysis, create new variables:",
   "id": "acbf580bddfaacbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T22:15:51.148139Z",
     "start_time": "2025-11-10T22:15:51.137789Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3612aa1e3240bde1",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_df_list_to_csv' from 'src.python.Functions' (/home/aidmantas/repos/Lithuanian-Innovation-Agency-Risk-Model/src/python/Functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Saving the final dataframes to csv files:\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFunctions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m save_df_list_to_csv\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Saving the final dataframes to csv files:\u001B[39;00m\n\u001B[1;32m      6\u001B[0m save_df_list_to_csv(joined_BP_list, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/interim/joined-balance-and-PnL/joined-only-mathing-ja-kodas\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'save_df_list_to_csv' from 'src.python.Functions' (/home/aidmantas/repos/Lithuanian-Innovation-Agency-Risk-Model/src/python/Functions.py)"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
