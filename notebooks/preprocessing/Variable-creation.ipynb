{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Variable creation",
   "id": "28e9426ea7b8984a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing libraries",
   "id": "bcb54c407c29d294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:19:43.192103Z",
     "start_time": "2025-11-18T09:19:42.868152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from src.python import read_large_file, create_variable_eval, set_columns_to_datetime\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'src', 'python')))\n",
    "from Functions import *"
   ],
   "id": "7c25c7dbb1b9c0b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing the dataset\n",
    "We will use the less filler datasets for this notebook."
   ],
   "id": "4f92ab110b1c49b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:19:45.876377Z",
     "start_time": "2025-11-18T09:19:43.201722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing the dataset\n",
    "\n",
    "# Full financial year, all ja_kodas codes.\n",
    "oFFAJKA2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2025_full_financial_year_all.csv')\n",
    "oFFAJKA2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2024_full_financial_year_all.csv')\n",
    "oFFAJKA2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2023_full_financial_year_all.csv')\n",
    "oFFAJKA2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2022_full_financial_year_all.csv')\n",
    "oFFAJKA2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2021_full_financial_year_all.csv')\n",
    "oFFAJKA2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2020_full_financial_year_all.csv')\n",
    "\n",
    "# Full financial year, mathing ja_kodas codes.\n",
    "oFFAJKM2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2025_full_financial_year_matching.csv')\n",
    "oFFAJKM2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2024_full_financial_year_matching.csv')\n",
    "oFFAJKM2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2023_full_financial_year_matching.csv')\n",
    "oFFAJKM2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2022_full_financial_year_matching.csv')\n",
    "oFFAJKM2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2021_full_financial_year_matching.csv')\n",
    "oFFAJKM2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2020_full_financial_year_matching.csv')\n",
    "\n",
    "#New firms included, all ja_kodas codes.\n",
    "oNFAJKA2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2025_all_firms_all.csv')\n",
    "oNFAJKA2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2024_all_firms_all.csv')\n",
    "oNFAJKA2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2023_all_firms_all.csv')\n",
    "oNFAJKA2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2022_all_firms_all.csv')\n",
    "oNFAJKA2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2021_all_firms_all.csv')\n",
    "oNFAJKA2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2020_all_firms_all.csv')\n",
    "\n",
    "#New firms included, matching ja_kodas codes.\n",
    "oNFAJKM2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2025_all_firms_matching.csv')\n",
    "oNFAJKM2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2024_all_firms_matching.csv')\n",
    "oNFAJKM2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2023_all_firms_matching.csv')\n",
    "oNFAJKM2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2022_all_firms_matching.csv')\n",
    "oNFAJKM2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2021_all_firms_matching.csv')\n",
    "oNFAJKM2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2020_all_firms_matching.csv')\n",
    "\n"
   ],
   "id": "863b964ecde35cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2025_full_financial_year_all.csv\n",
      "File size: 17.03 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 2531 rows (total: 132531)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 132531\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2024_full_financial_year_all.csv\n",
      "File size: 16.21 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 6352 rows (total: 126352)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 126352\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2023_full_financial_year_all.csv\n",
      "File size: 15.13 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 5097 rows (total: 125097)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 125097\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2022_full_financial_year_all.csv\n",
      "File size: 1.08 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 9979 rows (total: 9979)\n",
      "Concatenating 1 chunks...\n",
      "Finished reading. Total rows: 9979\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2021_full_financial_year_all.csv\n",
      "File size: 11.45 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 4514 rows (total: 94514)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 94514\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2020_full_financial_year_all.csv\n",
      "File size: 10.54 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6742 rows (total: 86742)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86742\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2025_full_financial_year_matching.csv\n",
      "File size: 16.39 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 384 rows (total: 130384)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 130384\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2024_full_financial_year_matching.csv\n",
      "File size: 15.61 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 4484 rows (total: 124484)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 124484\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2023_full_financial_year_matching.csv\n",
      "File size: 13.27 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 5929 rows (total: 105929)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 105929\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2022_full_financial_year_matching.csv\n",
      "File size: 0.94 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 7937 rows (total: 7937)\n",
      "Concatenating 1 chunks...\n",
      "Finished reading. Total rows: 7937\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2021_full_financial_year_matching.csv\n",
      "File size: 10.88 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6395 rows (total: 86395)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86395\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2020_full_financial_year_matching.csv\n",
      "File size: 10.02 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 9357 rows (total: 79357)\n",
      "Concatenating 8 chunks...\n",
      "Finished reading. Total rows: 79357\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2025_all_firms_all.csv\n",
      "File size: 18.49 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 10000 rows (total: 140000)\n",
      "Processed chunk 15 with 4336 rows (total: 144336)\n",
      "Concatenating 15 chunks...\n",
      "Finished reading. Total rows: 144336\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2024_all_firms_all.csv\n",
      "File size: 17.71 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 8564 rows (total: 138564)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 138564\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2023_all_firms_all.csv\n",
      "File size: 16.44 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 6578 rows (total: 136578)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 136578\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2022_all_firms_all.csv\n",
      "File size: 13.94 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 6768 rows (total: 116768)\n",
      "Concatenating 12 chunks...\n",
      "Finished reading. Total rows: 116768\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2021_all_firms_all.csv\n",
      "File size: 12.51 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 3744 rows (total: 103744)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 103744\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2020_all_firms_all.csv\n",
      "File size: 11.46 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 4664 rows (total: 94664)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 94664\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2025_all_firms_matching.csv\n",
      "File size: 17.79 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 10000 rows (total: 140000)\n",
      "Processed chunk 15 with 2174 rows (total: 142174)\n",
      "Concatenating 15 chunks...\n",
      "Finished reading. Total rows: 142174\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2024_all_firms_matching.csv\n",
      "File size: 17.06 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 6680 rows (total: 136680)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 136680\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2023_all_firms_matching.csv\n",
      "File size: 14.41 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 5651 rows (total: 115651)\n",
      "Concatenating 12 chunks...\n",
      "Finished reading. Total rows: 115651\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2022_all_firms_matching.csv\n",
      "File size: 13.14 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 5324 rows (total: 105324)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 105324\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2021_all_firms_matching.csv\n",
      "File size: 11.90 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 5060 rows (total: 95060)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 95060\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2020_all_firms_matching.csv\n",
      "File size: 10.91 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 15.0}\n",
      "Detected delimiter: ',' (score: 15.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6838 rows (total: 86838)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86838\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making copies of the dataframes\n",
    "We will make copies of the dataframes to avoid any unwanted modifications to the original dataframes."
   ],
   "id": "51fba313153a5539"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:19:46.200825Z",
     "start_time": "2025-11-18T09:19:45.973613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making copies of the dataframes\n",
    "\n",
    "# Full financial year, all ja_kodas codes.\n",
    "\n",
    "FFAJKA2025 = oFFAJKA2025.copy()\n",
    "FFAJKA2024 = oFFAJKA2024.copy()\n",
    "FFAJKA2023 = oFFAJKA2023.copy()\n",
    "FFAJKA2022 = oFFAJKA2022.copy()\n",
    "FFAJKA2021 = oFFAJKA2021.copy()\n",
    "FFAJKA2020 = oFFAJKA2020.copy()\n",
    "\n",
    "# Full financial year, matching ja_kodas codes.\n",
    "\n",
    "FFAJKM2025 = oFFAJKM2025.copy()\n",
    "FFAJKM2024 = oFFAJKM2024.copy()\n",
    "FFAJKM2023 = oFFAJKM2023.copy()\n",
    "FFAJKM2022 = oFFAJKM2022.copy()\n",
    "FFAJKM2021 = oFFAJKM2021.copy()\n",
    "FFAJKM2020 = oFFAJKM2020.copy()\n",
    "\n",
    "#New firms included, all ja_kodas codes.\n",
    "\n",
    "NFAJKA2025 = oNFAJKA2025.copy()\n",
    "NFAJKA2024 = oNFAJKA2024.copy()\n",
    "NFAJKA2023 = oNFAJKA2023.copy()\n",
    "NFAJKA2022 = oNFAJKA2022.copy()\n",
    "NFAJKA2021 = oNFAJKA2021.copy()\n",
    "NFAJKA2020 = oNFAJKA2020.copy()\n",
    "\n",
    "#New firms included, matching ja_kodas codes.\n",
    "\n",
    "NFAJKM2025 = oNFAJKM2025.copy()\n",
    "NFAJKM2024 = oNFAJKM2024.copy()\n",
    "NFAJKM2023 = oNFAJKM2023.copy()\n",
    "NFAJKM2022 = oNFAJKM2022.copy()\n",
    "NFAJKM2021 = oNFAJKM2021.copy()\n",
    "NFAJKM2020 = oNFAJKM2020.copy()\n",
    "\n",
    "# Saving in lists for ease of use.\n",
    "\n",
    "FFAJKA = [FFAJKA2025, FFAJKA2024, FFAJKA2023, FFAJKA2022, FFAJKA2021, FFAJKA2020]\n",
    "FFAJKM = [FFAJKM2025, FFAJKM2024, FFAJKM2023, FFAJKM2022, FFAJKM2021, FFAJKM2020]\n",
    "NFAJKA = [NFAJKA2025, NFAJKA2024, NFAJKA2023, NFAJKA2022, NFAJKA2021, NFAJKA2020]\n",
    "NFAJKM = [NFAJKM2025, NFAJKM2024, NFAJKM2023, NFAJKM2022, NFAJKM2021, NFAJKM2020]\n",
    "\n",
    "ALL_DATA = [FFAJKA, FFAJKM, NFAJKA, NFAJKM]"
   ],
   "id": "666a37025fb506f4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating variables\n",
   "id": "bf8e6297f90f8884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:34:50.225237Z",
     "start_time": "2025-11-18T09:34:49.773550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TURTAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'TURTAS', '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`')\n",
    "\n",
    "# GRYNOJO PELNO MARZA variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'GRYNOJO PELNO MARŽA (procentais)', '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100')\n",
    "\n",
    "# TURTO APYVARTUMAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'TURTO APYVARTUMAS (santykis)', '`TURTAS` / `PARDAVIMO PAJAMOS`')\n",
    "\n",
    "# ROA variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'ROA (procentais)', '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100')\n",
    "\n",
    "# VĖLUOJANČIOS ATASKAITOS variable, reg_date of pnl or balance is after 05-30\n",
    "Y2025 = [FFAJKA2025, FFAJKM2025, NFAJKA2025, NFAJKM2025]\n",
    "Y2024 = [FFAJKA2024, FFAJKM2024, NFAJKA2024, NFAJKM2024]\n",
    "Y2023 = [FFAJKA2023, FFAJKM2023, NFAJKA2023, NFAJKM2023]\n",
    "Y2022 = [FFAJKA2022, FFAJKM2022, NFAJKA2022, NFAJKM2022]\n",
    "Y2021 = [FFAJKA2021, FFAJKM2021, NFAJKA2021, NFAJKM2021]\n",
    "Y2020 = [FFAJKA2020, FFAJKM2020, NFAJKA2020, NFAJKM2020]\n",
    "\n",
    "set_columns_to_datetime(Y2025, ['reg_date_pnl', 'reg_date_balance'], inplace=True)\n",
    "\n",
    "create_variable_eval(Y2025, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")')\n",
    "create_variable_eval(Y2024, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")')\n",
    "create_variable_eval(Y2023, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")')\n",
    "create_variable_eval(Y2022, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")')\n",
    "create_variable_eval(Y2021, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")')\n",
    "create_variable_eval(Y2020, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")')\n",
    "\n",
    "\n",
    "# SVERTINIS MOKUMO PAKAITALAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'SVERTINIS MOKUMO PAKAITALAS (santykis)', '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`')\n",
    "\n"
   ],
   "id": "a8acec94d65bf247",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "⚠️  INPLACE MODE: Modifying original DataFrame(s)\n",
      "\n",
      "Processing DataFrame 0 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 1 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 2 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 3 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_processed': 24,\n",
       " 'successful': 24,\n",
       " 'failed': 0,\n",
       " 'errors': [],\n",
       " 'formula_used': '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`',\n",
       " 'inplace': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merging date columns\n",
   "id": "c44006c3dced40d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:43:34.699817Z",
     "start_time": "2025-11-18T09:43:34.617445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Merging date columns\n",
    "\n",
    "coalesce_columns(, ['beginning_date_balance', 'beginning_date_pnl'], 'beginning_date')\n",
    "\n",
    "coalesce_columns(, ['turning_date_balance', 'turning_date_pnl'], 'turning_date')\n",
    "\n",
    "# Merging reg_date_balance and reg_date_pnl for simplicity\n",
    "\n",
    "coalesce_columns(, ['reg_date_balance','reg_date_pnl'], 'reg_date')\n"
   ],
   "id": "a1db2f6a076ec34e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DataFrame 0: 'list' object has no attribute 'columns'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Merging date columns\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mcoalesce_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mALL_DATA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbeginning_date_balance\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbeginning_date_pnl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbeginning_date\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m coalesce_columns(ALL_DATA, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mturning_date_balance\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mturning_date_pnl\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mturning_date\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Merging reg_date_balance and reg_date_pnl for simplicity\u001B[39;00m\n",
      "File \u001B[0;32m~/repos/Lithuanian-Innovation-Agency-Risk-Model/src/python/Functions.py:2251\u001B[0m, in \u001B[0;36mcoalesce_columns\u001B[0;34m(dataframes, columns, new_column_name, method, inplace)\u001B[0m\n\u001B[1;32m   2248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df_result\n\u001B[1;32m   2250\u001B[0m \u001B[38;5;66;03m# Handle inplace operation using shared logic\u001B[39;00m\n\u001B[0;32m-> 2251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_process_dataframes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoalesce_single_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcoalesced\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_column_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/Lithuanian-Innovation-Agency-Risk-Model/src/python/Functions.py:2365\u001B[0m, in \u001B[0;36m_process_dataframes\u001B[0;34m(dataframes, processing_function, operation_name, columns, new_column_name, inplace, method)\u001B[0m\n\u001B[1;32m   2363\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, df \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataframes_list):\n\u001B[1;32m   2364\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2365\u001B[0m         original_columns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m)\n\u001B[1;32m   2366\u001B[0m         result_df \u001B[38;5;241m=\u001B[39m processing_function(df)\n\u001B[1;32m   2368\u001B[0m         \u001B[38;5;66;03m# Clear the original DataFrame but preserve its identity\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9e1fc42b336ad555"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
